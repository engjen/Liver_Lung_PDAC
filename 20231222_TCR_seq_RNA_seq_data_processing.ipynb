{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process TCRseq and RNAseq\n",
    "\n",
    "**RNA**\n",
    "- pearson correlation between pORG and --\n",
    "- deconvolution\n",
    "- GSVA\n",
    "- gene expression\n",
    "\n",
    "\n",
    "**TCR**\n",
    "- calculate shared/clonal TCR clonotypes\n",
    "- Count KRAS specific clonotypes\n",
    "- Calculate Shannon entropy, clonality and Simpson's D\n",
    "\n",
    "***Sample exclusion*** \n",
    " - ST-00021096-B was excluded from analysis because it was collected 417 days before the patient was diagnosed with PDAC. All other matched bloods are collected post diagnosis. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load libraries\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import math\n",
    "import warnings\n",
    "from scipy.stats import pearsonr\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "from matplotlib import cm, gridspec\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "mpl.rc('figure', max_open_warning = 0)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import minmax_scale, scale, FunctionTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import lifelines\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from lifelines.statistics import multivariate_logrank_test\n",
    "from lifelines import exceptions\n",
    "warnings.filterwarnings(\"ignore\",category = exceptions.ApproximationWarning)\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import entropy, norm\n",
    "from scipy.spatial import cKDTree\n",
    "import networkx as nx\n",
    "import statsmodels\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import statsmodels.api as sm\n",
    "import pylab\n",
    "\n",
    "import anndata\n",
    "from anndata import AnnData\n",
    "from bioinfokit import analys, visuz\n",
    "\n",
    "#import phenograph\n",
    "\n",
    "codedir = os.getcwd()#'/home/groups/BCC_Chin_Lab/ChinData/Cyclic_Analysis/cmIF_2021-05-03_PDAC/U54-TMA-9/Jenny'  #\n",
    "#rootdir = '/home/groups/BCC_Chin_Lab/ChinData/Cyclic_Analysis/cmIF_2021-05-03_PDAC/U54-TMA-9'\n",
    "# os.chdir('/home/groups/graylab_share/Chin_Lab/ChinData/engje/Data')\n",
    "# from mplex_image import visualize as viz, process, preprocess, normalize, mics, mpimage\n",
    "# from spatial import spatial\n",
    "\n",
    "import plotly.express as px\n",
    "from statannotations.Annotator import Annotator\n",
    "from itertools import combinations\n",
    "import util\n",
    "np.random.seed(712)\n",
    "\n",
    "#change to correct directory\n",
    "datadir = f'{codedir}/data'\n",
    "s_date = '20230914'\n",
    "os.chdir(codedir)\n",
    "if not os.path.exists(s_date):\n",
    "    os.mkdir(s_date)\n",
    "    os.mkdir(f'{s_date}/Survival_Plots')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents <a name=\"contents\"></a>\n",
    "\n",
    "1. [**RNAseq data for validation**](#rna) [Pearson Correlation](#rnacorr) [DEseq2](#rnadeseq) [Categorical GSVA](#rnagsva)\n",
    "2. [TCRseq data](#tcr) [Shared/Clonal](#sharedclonal)\n",
    "   [**TCR KRAS**](#kras)\n",
    "\n",
    "   [**TCR number**](#tcrnum) [**TCR pie charts**](#tcrpie) [TCRseq metrics](#tcr2)\n",
    "\n",
    "   [OLD](#old) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNAseq analysis <a name=\"rna\"></a> \n",
    "\n",
    "[contents](#contents)\n",
    "\n",
    "ran DESeq2, GSVA, deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient = pd.read_excel('Supplemental_Data/Supplemental_Dataset_1.xlsx',sheet_name=0,\n",
    "                          index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # deconv processing\n",
    "# a = 'Tempus300'#\n",
    "# # # Python to translate ensembl to gene name: done\n",
    "# df_annot = pd.read_csv(f\"../R/results/results_annotation_{a}.csv\",index_col=0)\n",
    "# df_annot.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = 'Tempus300'#\n",
    "# df_tpm = pd.read_csv(f\"results/results_TPM_{a}.csv\",index_col=0)\n",
    "# # if df_tpm.index[0].find('.')>-1: #periods\n",
    "# #     df_tpm.index = [item.split('.')[0] for item in df_tpm.index]\n",
    "# df_tpm.index = df_tpm.index.map(dict(zip(df_annot.gene_id,df_annot.gene_name)))\n",
    "# print(len(df_tpm))\n",
    "# print(len(df_tpm[~df_tpm.index.duplicated(keep='first')]))\n",
    "# df_tpm_sum = df_tpm.groupby(by=df_tpm.index, axis=0).sum()\n",
    "# print(len(df_tpm_sum))\n",
    "# df_tpm_sum.to_csv(f\"results_TPM_{a}_sum.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tpm_sum.loc[:,df_tpm_sum.columns.str.contains('-T')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load deconvolution - dowload from synapse!\n",
    "# https://www.synapse.org/Synapse:syn53977850\n",
    "\n",
    "df_deconv = pd.DataFrame()\n",
    "#for s_deconv in ['QTS','EPC']: #QTS is  immune freq, XCL and 'MCP', has states\n",
    "ls_deconv_data = ['QTS','EPC','MCP']\n",
    "#ls_deconv_data = ['XCL']\n",
    "\n",
    "for s_deconv in ls_deconv_data:#,'MCP''XCL'\n",
    "    df_epc = pd.read_csv(f'data/results_{s_deconv}_deconv.csv',index_col=0)#.drop('Unnamed: 0',axis=1).set_index('cell_type')\n",
    "    if len(ls_deconv_data) >1:\n",
    "        df_epc.columns = [f'{item} {s_deconv}' for item in df_epc.columns]\n",
    "    df_deconv = pd.concat([df_deconv,df_epc],axis=1)\n",
    "ls_marker = df_deconv.columns.tolist()\n",
    "ls_deconv = ls_marker\n",
    "#df_deconv.T.head()\n",
    "print(len(df_deconv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_ids = pd.read_excel(f'{codedir.split(\"Liver_Lung_PDAC\")[0]}MethodsAndReferencesSupplementalData/OLD Versions/Simplified_Public_IDs_Key.xlsx',sheet_name=None)\n",
    "\n",
    "# df_id = d_ids['RnaSeqKey']\n",
    "# ls_ids = df_id.loc[:,'Public.Specimen.ID']\n",
    "\n",
    "# # add patients w/o RNA seq\n",
    "# for s_key in ['TcrTumorKey','TcrBloodKey','SuppTable2Key','DnaPanelKey']:\n",
    "#     df_add = d_ids[s_key].loc[~d_ids[s_key].loc[:,'Public.Specimen.ID'].isin(ls_ids)]\n",
    "#     df_id = pd.concat([df_id,df_add])\n",
    "# df_deconv = df_deconv.T\n",
    "# d_mapper = dict(zip(df_id.loc[:,'Public.Specimen.ID'],df_id.loc[:,'OPTR.Specimen.ID']))\n",
    "# df_spec =  pd.read_excel('Supplemental_Data/Supplemental_Dataset_1.xlsx',sheet_name='RNA_Specimen_Metadata',\n",
    "#                           index_col=0)\n",
    "# df_spec['OPTR_ID'] = df_spec.Public_Specimen_ID.map(d_mapper)\n",
    "# d_public = dict(zip(df_spec.OPTR_ID,df_spec.Public_Specimen_ID))\n",
    "# df_deconv.index = df_deconv.index.map(d_public)\n",
    "# df_deconv.index.name = 'Patient'\n",
    "# df_deconv = df_deconv[df_deconv.index.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_spec =  pd.read_excel('Supplemental_Data/Supplemental_Dataset_1.xlsx',sheet_name='RNA_Specimen_Metadata',\n",
    "                           index_col=0)\n",
    "for s_score in ['pORG_Up_55_Primaries','pSUB_Up_51_Primaries']:\n",
    "    d_score = dict(zip(df_spec.Public_Specimen_ID,df_spec.loc[:,s_score]))\n",
    "    df_deconv[s_score] = df_deconv.index.map(d_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#correlation heatmap\n",
    "\n",
    "ls_drop = [ 'Tumor_Cellularity','stroma score','Common lymphoid progenitor',\n",
    " 'Common myeloid progenitor','Granulocyte-monocyte progenitor','uncharacterized cell',\n",
    " 'immune score','microenvironment score','uncharacterized cell QTS','uncharacterized cell EPC',\n",
    "           'Cancer associated fibroblast','Endothelial cell','Hematopoietic stem cell',]\n",
    "ls_drop = [ 'Tumor_Cellularity','Common lymphoid progenitor','stroma score',#'Cancer associated fibroblast','Endothelial cell',\n",
    " 'Common myeloid progenitor','Granulocyte-monocyte progenitor','uncharacterized cell',\n",
    " 'immune score','microenvironment score','uncharacterized cell QTS','uncharacterized cell EPC',\n",
    "           'Hematopoietic stem cell',]\n",
    "df_all = df_deconv.loc[:,ls_marker + ['pORG_Up_55_Primaries']] #'pORG.14',,'Tumor_Cellularity_by_DNA_Primary'\n",
    "df_all.rename({'pORG_Up_55_Primaries':'pORG Primary',\n",
    "              'Tumor_Cellularity_by_DNA_Primary':'Tumor_Cellularity'},axis=1,inplace=True)\n",
    "s_add = 'pORG Primary'\n",
    "df_all = df_all.loc[:,~df_all.columns.isin(ls_drop)]\n",
    "if len(ls_deconv_data) > 1:\n",
    "    s_deconv= \".\".join(ls_deconv_data)\n",
    "    dim = (7.7,6.2)\n",
    "else:\n",
    "    dim = (5,4)\n",
    "if ls_deconv_data == ['XCL']:\n",
    "    dim = (7.7,6.2)\n",
    "g = sns.clustermap(df_all.corr())\n",
    "plt.close()\n",
    "categories_order = df_all.corr().iloc[g.dendrogram_col.reordered_ind,:].index.tolist()\n",
    "df_all = df_all.loc[:,categories_order]\n",
    "rho = df_all.corr()\n",
    "pval = df_all.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "#p_vals = pval.applymap(lambda x: ''.join(['*' for t in [0.05] if x<=t])) #0.001,0.005,\n",
    "#fdr correct\n",
    "pvalues = pval.loc[s_add,~pval.columns.isin([s_add])]\n",
    "reject, corrected, __, __ = statsmodels.stats.multitest.multipletests(pvalues,method='fdr_bh')\n",
    "df_corrected = pd.DataFrame(np.ones_like(pval),index=pval.index,columns=pval.columns)\n",
    "df_corrected.loc[s_add,~df_corrected.columns.isin([s_add])] = corrected\n",
    "df_corrected.loc[~df_corrected.columns.isin([s_add]),s_add] = corrected\n",
    "p_vals = df_corrected.applymap(lambda x: ''.join(['*' for t in [0.001,0.005,0.05] if x<=t]))\n",
    "p_vals = p_vals.loc[categories_order,categories_order]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=dim,dpi=600)\n",
    "sns.heatmap(df_all.corr(), vmin=-1, vmax=1, annot=p_vals, fmt = '',annot_kws={'size':'x-small'},\n",
    "            cmap='RdBu_r',ax=ax,yticklabels=1,xticklabels=1,cbar_kws={'shrink':0.75,'label':'Pearson Correlation'})\n",
    "ax.set_title(f'N={len(df_all)}')#, fontdict={'fontsize':14}, pad=12)\n",
    "ax.set_xticklabels([item.get_text()[0:15] for item in ax.get_xticklabels()])\n",
    "plt.tight_layout()\n",
    "if len(ls_deconv_data)==3:\n",
    "    fig.savefig(f'figures/Deconvolution3.pdf')\n",
    "else:\n",
    "    fig.savefig(f'figures/Xcell.pdf')\n",
    "    print('main')\n",
    "    d_fig4.update({f'Figure4_A':df_all.corr()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(f'{item:.2}') for item in df_corrected.loc[categories_order,'pORG Primary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rho.to_csv(f'Source_Extended_Data_Figure6_H.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[print(f'{item:.3}')  for item in corrected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#util.open_write_excel(d_fig4,filename='Source_Data_Figure4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #new scores: save identified\n",
    "# df_id = pd.read_csv('Patient_IDs.csv',index_col=0)#.rename({'Biolibrary.Subject.ID':'Public_Patient_ID',\n",
    "#                                                    #       'Public.Specimen.ID':'Public_Specimen_ID'},axis=1)\n",
    "# df_scores = pd.DataFrame()\n",
    "\n",
    "# ls_score = ['GSVA_PrimarySamplesReports.xlsx','GSVA_MetSamplesReports.xlsx','GSVA_AllSamplesReports.xlsx']\n",
    "# for s_score in ls_score:\n",
    "#     df = pd.read_excel(f'./annotation/{s_score}',sheet_name=1)\n",
    "#     df['Public_Specimen_ID'] = df.Sample.map(dict(zip(df_id.loc[:,'OPTR.Specimen.ID'],df_id.loc[:,'Public.Specimen.ID'])))\n",
    "#     df['Group'] = s_score.split('Samples')[0]\n",
    "#     #df.drop('Sample',axis=1,inplace=True)\n",
    "#     df_scores = pd.concat([df_scores,df])\n",
    "\n",
    "# df_scores.to_csv('20230608_GSVA_Scores.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gene, GSVA correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # using non-public IDs, can't share files\n",
    "# #sorted(os.listdir('../R/DESeq2'))\n",
    "# #os.listdir('../R/')\n",
    "# df_gsva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df_patient = pd.read_excel('Supplemental_Data/Supplemental_Dataset_1.xlsx',sheet_name=0,\n",
    "                          index_col=0)\n",
    "# load gsva - dowload from synapse!\n",
    "# https://www.synapse.org/Synapse:syn53977850\n",
    "df_gsva = pd.read_csv('data/results_GSVA_deidentified.csv',index_col=0)\n",
    "df_gsva.index = [item.replace('X','').replace('.','-') for item in df_gsva.index]\n",
    "df_gsva.rename({'neutrophil activation involved in immune response':'neut. act. invol. in imm. resp.',\n",
    "               'T cell activation involved in immune response':'T cell act. invol. in imm. resp.'},axis=1,inplace=True)\n",
    "\n",
    "#NOTE: upload the annotations\n",
    "# df_annotation = pd.read_csv('../R/DESeq2/DESeq2_annotation.csv',index_col=0)\n",
    "# d_annotation = dict(zip(df_annotation.gene_id,df_annotation.gene_name))\n",
    "\n",
    "# df_vst = pd.read_csv('../R/DESeq2/DESeq2_matrix_downstream.csv',index_col=0) #2\n",
    "# df_vst.index = df_vst.index.map(d_annotation)\n",
    "\n",
    "# #df_gene = df_pri.merge(df_vst.T,left_index=True,right_index=True) #old pORG\n",
    "# df_gene = df_vst.T.copy().reset_index().rename({'index':'ID'},axis=1)\n",
    "# df_gene.rename({'Patient Specimen ID':'Public_Specimen_ID'},axis=1,inplace=True)\n",
    "# df_gene = df_gene.set_index('ID')\n",
    "# df_gene = df_gene[~df_gene.index.duplicated()]\n",
    "\n",
    "# load rna - dowload from synapse!\n",
    "# https://www.synapse.org/Synapse:syn53977850\n",
    "df_gene = pd.read_csv(f'data/VST_Genes_Link.csv',index_col=0)\n",
    "df_gene = df_gene.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gene correlation <a name=\"rnacorr\"></a> \n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # correlation heatmap TCR data with genes, hallmarks and deconvolution (plus pORG\n",
    "# df_tcr = pd.read_csv(f'annotation/20231012_Patient_Metadata_TCR_Metrics.csv',index_col=0)\n",
    "\n",
    "# ls_scores =['pORG_0.2_Primary']#['trim_padj_0.2_pORG_Up_55_Genes','Kallisto55_pSUB1e-04','PurIST Score']\n",
    "# ls_tcr = ['Simpsons_Evenness_Tumor', 'Simpsons_Evenness_Blood', \n",
    "#        'Shannon_Entropy_Tumor','Templates_per_ng',\n",
    "#        'Normalized_Shannon_Entropy_Tumor', 'Shannon_Entropy_Blood',\n",
    "#        'Normalized_Shannon_Entropy_Blood', 'Fraction Shared TCRs',\n",
    "#        'Simpsons_Diversity_Tumor','Age at Diagnosis',\n",
    "#        'Simpsons_Diversity_Blood', 'Clonality_Tumor', 'Clonality_Blood',\n",
    "#        'Percent Tumor Distinct Clones','pORG_0.2_Primary']\n",
    "\n",
    "# ls_tcr = ['Simpsons_Evenness_Tumor',# 'Simpsons_Evenness_Blood', \n",
    "#        'Shannon_Entropy_Tumor','Templates_per_ng',\n",
    "#        #'Normalized_Shannon_Entropy_Tumor', 'Shannon_Entropy_Blood',\n",
    "#        #'Normalized_Shannon_Entropy_Blood', 'Fraction Shared TCRs',\n",
    "#        #'Simpsons_Diversity_Tumor','Age at Diagnosis',\n",
    "#        #'Simpsons_Diversity_Blood', \n",
    "#           'Clonality_Tumor',# 'Clonality_Blood',\n",
    "#        #'Percent Tumor Distinct Clones',\n",
    "#       'Productive_Rearrangements',#'pORG_Primary'\n",
    "#     ]\n",
    "\n",
    "ls_gsva = df_gsva.columns[~df_gsva.columns.str.contains('HALLMARK')]\n",
    "ls_gsva = ls_gsva.drop('Stem (dan broeck)').tolist()\n",
    "ls_hallmark = df_gsva.columns[df_gsva.columns.str.contains('HALLMARK')].tolist()\n",
    "ls_hallmark_select = ['HALLMARK_MYC_TARGETS_V1',#'HALLMARK_IL2_STAT5_SIGNALING','HALLMARK_IL6_JAK_STAT3_SIGNALING','HALLMARK_INFLAMMATORY_RESPONSE',\n",
    "        'HALLMARK_E2F_TARGETS', 'HALLMARK_MITOTIC_SPINDLE',#'HALLMARK_DNA_REPAIR',\n",
    "       'HALLMARK_MTORC1_SIGNALING','HALLMARK_G2M_CHECKPOINT','neutrophil_degranulation',\n",
    "              'T cells','B cells','REACTOME_NEUTROPHIL_DEGRANULATION','GOCC_AZUROPHIL_GRANULE',\n",
    "               'GOCC_TERTIARY_GRANULE','GOCC_SPECIFIC_GRANULE']\n",
    "\n",
    "ls_gsva_ifn = ['T cells','B cells','response to type II interferon',#'HALLMARK_MYC_TARGETS_V1',\n",
    "               'cellular response to type I interferon','IRDS',]\n",
    "ls_krt_select = ['CXCL5','CDC42','RAB11A','NUMB','HPSE','LCN2','MPO']\n",
    "ls_krt= []\n",
    "ls_test = ['MKI67','HLA-DQB1','HLA-DRB1','HLA-DRB9','HLA-DQA1','HLA-DRB5',\n",
    " 'HLA-DOA', 'HLA-DMA','HLA-DRA','HLA-DQB1-AS1','HLA-DPB1','HLA-DPB2',\n",
    " 'HLA-DRB6','HLA-DPA1','HLA-DQB2','HLA-DQA2','HLA-DOB','HLA-DMB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_gene.merge(df_gsva.loc[:,ls_gsva + ls_hallmark], #loc[~df_gene.loc[:,ls_scores[0]].isna(),:]\n",
    "                    left_index=True,right_index=True)\n",
    "df_plot['Public_Patient_ID'] =['ST-'+item.split('-')[1] for item in df_plot.index]\n",
    "# #get IDs\n",
    "# d_ids = pd.read_excel(f'{codedir.split(\"Liver_Lung_PDAC\")[0]}MethodsAndReferencesSupplementalData/OLD Versions/Simplified_Public_IDs_Key.xlsx',sheet_name=None)\n",
    "# df_id = d_ids['RnaSeqKey']\n",
    "# df_plot['Public_Patient_ID'] = df_plot.index.map(dict(zip(df_id.loc[:,'OPTR.Specimen.ID'],df_id.loc[:,'Biolibrary.Subject.ID'])))\n",
    "# #df_plot.dropna().set_index('Public_Patient_ID').to_csv(f'results/Patient_summary_GSVA.csv')\n",
    "# df_deconv['Public_Patient_ID'] = df_deconv.index.map(dict(zip(df_id.loc[:,'OPTR.Specimen.ID'],df_id.loc[:,'Biolibrary.Subject.ID'])))\n",
    "# #df_deconv.merge(df_patient,on='Public_Patient_ID',how='left')\n",
    "df_plot = df_plot.merge(df_patient,on='Public_Patient_ID',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X cell\n",
    "ls_deconv = ['Myeloid dendritic cell activated','B cell',\n",
    " 'T cell CD4+ memory','T cell CD4+ naive','T cell CD4+ (non-regulatory)',\n",
    " 'T cell CD4+ central memory','T cell CD4+ effector memory','T cell CD8+ naive',\n",
    " 'T cell CD8+','T cell CD8+ central memory', 'T cell CD8+ effector memory','Class-switched memory B cell',\n",
    " 'Common lymphoid progenitor','Common myeloid progenitor','Myeloid dendritic cell',\n",
    " 'Endothelial cell','Eosinophil','Cancer associated fibroblast',\n",
    " 'Granulocyte-monocyte progenitor','Hematopoietic stem cell',\n",
    " 'Macrophage','Macrophage M1', 'Macrophage M2','Mast cell','B cell memory',\n",
    " 'Monocyte','B cell naive','Neutrophil','NK cell','T cell NK','Plasmacytoid dendritic cell',\n",
    " 'B cell plasma','T cell gamma delta','T cell CD4+ Th1','T cell CD4+ Th2',\n",
    "'T cell regulatory (Tregs)',]\n",
    " #'immune score',\n",
    " #'stroma score',\n",
    " #'microenvironment score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "d_result_fig = {}\n",
    "s_add = 'pORG_Primary'\n",
    "d_correlate = {'IFN GSVA':(df_plot,ls_gsva_ifn),\n",
    "              # 'MHCII':(df_plot,ls_test+ls_gsva_ifn),\n",
    "              #  'GSVA/Gene Expression':(df_plot,ls_hallmark_select+ls_krt_select),\n",
    "              #  'Hallmarks':(df_gsva,ls_hallmark_select),\n",
    "              #  'Immune Gene Signatures':(df_gsva,ls_gsva),\n",
    "              #  'Gene Expression':(df_gene,ls_krt),\n",
    "               #'Deconvolution':(df_deconv.merge(df_plot,on='Public_Patient_ID',how='left'),ls_deconv + ls_gsva_ifn)\n",
    "              }\n",
    "d_rename = {'neutrophil_degranulation':'GO_NEUTROPHIL_DEGRANULATION',\n",
    "            'response to type II interferon':'RESPONSE_TYPE_II_IFN',\n",
    "            'cellular response to type I interferon':'CELL_RESPONSE_TYPE_I_IFN',\n",
    "            'T cells':'IMSIG_T_CELLS','B cells':\"IMSIG_B_CELLS\"}\n",
    "for s_merge, tu in d_correlate.items():\n",
    "    df = tu[0]\n",
    "    ls_col = tu[1]\n",
    "    #limit to primary tumors\n",
    "    #df_plot = df_tcr_pri.loc[df_tcr_pri.Tumor_Type == 'Primary',ls_tcr].merge(df.loc[:,ls_col],left_index=True,right_index=True)\n",
    "    try:\n",
    "        df_plot['Age at Diagnosis'] = df_plot.loc[:,'Age at Diagnosis'].astype('float64')\n",
    "    except:\n",
    "        pass\n",
    "    df_all = df.loc[:,(df.dtypes=='float64') & (~df.columns.duplicated())].copy()\n",
    "    df_all = df_all.loc[:,ls_col + ['pORG_Primary']]\n",
    "    df_all.rename(d_rename,axis=1,inplace=True)\n",
    "    dim = (5,4.2)\n",
    "    if s_merge == 'Deconvolution':\n",
    "        dim = (11,9)\n",
    "    g = sns.clustermap(df_all.corr())\n",
    "    plt.close()\n",
    "    categories_order = df_all.corr().iloc[g.dendrogram_col.reordered_ind,:].index.tolist()\n",
    "    df_all = df_all.loc[:,categories_order]\n",
    "    rho = df_all.corr()\n",
    "    #pval = df_all.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "    pval = df_all.corr(method=lambda x, y: stats.spearmanr(x, y)[1]) - np.eye(*rho.shape)\n",
    "    #p_vals = pval.applymap(lambda x: ''.join(['*' for t in [0.05] if x<=t])) #0.001,0.005,\n",
    "    #fdr correct\n",
    "    pvalues = pval.loc[s_add,~pval.columns.isin([s_add])]\n",
    "    reject, corrected, __, __ = statsmodels.stats.multitest.multipletests(pvalues,method='fdr_bh')\n",
    "    df_corrected = pd.DataFrame(np.ones_like(pval),index=pval.index,columns=pval.columns)\n",
    "    df_corrected.loc[s_add,~df_corrected.columns.isin([s_add])] = corrected\n",
    "    df_corrected.loc[~df_corrected.columns.isin([s_add]),s_add] = corrected\n",
    "    p_vals = df_corrected.applymap(lambda x: ''.join(['*' for t in [0.001,0.005,0.05] if x<=t]))\n",
    "    p_vals = p_vals.loc[categories_order,categories_order]\n",
    "    fig, ax = plt.subplots(figsize=dim,dpi=300)\n",
    "    sns.heatmap(df_all.corr(), vmin=-1, vmax=1, annot=p_vals, fmt = '', cmap='RdBu_r',\n",
    "                ax=ax,yticklabels=1,xticklabels=1,cbar_kws={'shrink':0.85,'label':'Pearson Correlation'})\n",
    "    ax.set_title(f'N={len(df_all)}')\n",
    "    #ax.set_title(f'TCR Metrics vs. {s_merge}', fontdict={'fontsize':16}, pad=12)\n",
    "    #if len(ls_tcr) == 1:\n",
    "    #ax.set_title(f'pORG Primary vs. {s_merge}', fontdict={'fontsize':16}, pad=12)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f'figures/heatmap_pORG_Primary_vs_{s_merge}.pdf')\n",
    "    #d_result_fig.update({f'Figure3_J_pORG_vs_{s_merge}':df_all.corr()})\n",
    "    #util.open_write_excel(d_result_fig,filename='Source_Data_Figure3.xlsx')\n",
    "    #break #'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(f'{item:.2}') for item in df_corrected.rename(d_rename).loc[categories_order].pORG_Primary]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## krt tertiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for s_marker in ['KRT19','KRT5']:\n",
    "#     df_krt = df_surv_all.drop('leiden',axis=1).copy()\n",
    "#     se_tertile = pd.qcut(df_gene.loc[df_surv_all.index,s_marker].drop_duplicates(),q=[0,.33,.66,1],labels=['low','med','high'])\n",
    "#     df_krt['leiden'] = df_krt.index.map(se_tertile)\n",
    "#     df_krt = df_krt.drop_duplicates()\n",
    "#     util.km_cph(df_krt.dropna())\n",
    "#     plt.suptitle(f'{s_marker}',y=1)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # KRT19 tertile\n",
    "# df_all['KRT19_tertile'] = df_all.index.map(df_krt.leiden)\n",
    "# d_color=dict(zip(['high','med','low'],palette))\n",
    "# figsize=(15,5.5)\n",
    "# df_clust_map = df_all.groupby('KRT19_tertile').mean()\n",
    "# row_colors = df_clust_map.index.astype('str').map(d_color)\n",
    "# g = sns.clustermap(df_clust_map,xticklabels=1,cmap='viridis',z_score=1,vmin=-1.3,vmax=1.3,\n",
    "#                   dendrogram_ratio=0.1, cbar_pos=(.04, 0.92, 0.03, 0.10),figsize=figsize,method='complete',\n",
    "#                    row_colors=row_colors)\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_plot.to_csv('results_primaries_KRT19_subtypes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_surv_all.to_csv('results_primaries_leiden_subtypes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEseq2 <a name=\"rnadeseq\"></a> \n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_marker = pd.read_csv('annotation/PanglaoDB_markers_27_Mar_2020.tsv',sep='\\t') \n",
    "# #pdac data set\n",
    "# df_marker2 = pd.read_csv('annotation/PAAD_GSE111672_AllDiffGenes_table.tsv',sep='\\t')\n",
    "# df_marker3 = pd.read_csv('annotation/PAAD_CRA001160_AllDiffGenes_table.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls_neut2= df_marker2[df_marker2.loc[:,'Celltype (major-lineage)']=='Neutrophils'].Gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ls_neut= df_marker.loc[df_marker.loc[:,'cell type']=='Neutrophils','official gene symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results[(df_results.padj<0.1)& (df_results.gene_name.isin(ls_neut))].sort_values(by='log2FoldChange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results[(df_results.padj<0.1) & (df_results.gene_name.isin(ls_neut2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results[(df_results.padj>0.1) & (df_results.gene_name.isin(ls_neut2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #neutrophil genes are lower in lung\n",
    "# ls_gene = ['CXCR1','CXCR2','CXCL1', 'CXCL2', 'CXCL3', 'CXCL5', 'CXCL6', 'CXCL7', 'CXCL8','CCRL2',#neutophils\n",
    "#            'CCR2','CCL2','CD68','CCL8','CCL7',#macs\n",
    "#           'CD3E','CD4','CD8A','CCL21','IL2','XCL1',\n",
    "#            'CCR5','CXCR3','CCR7','CCL5','CCL3','CXCL9','CXCL10','CCL21','CCL19',# Tcell recruitment\n",
    "#           'CD44','CDH1','KRT19','KRT7','KRT8','KRT5','KRT17'] #epithelial \n",
    "# for s_gene in ls_gene:\n",
    "#     if (df_results.loc[df_results.gene_name == s_gene,'pvalue'] < 0.05).any():\n",
    "#             print(df_results.loc[df_results.gene_name == s_gene,['pvalue','padj','gene_name','log2FoldChange']])\n",
    "#             print(df_marker.loc[df_marker.loc[:,'official gene symbol']==s_gene,'cell type'])\n",
    "    \n",
    "# ls_gene = df_marker[(df_marker.loc[:,'cell type']=='Neutrophils')&(df_marker.species.str.contains('Hs'))].sort_values(\n",
    "#     by='ubiquitousness index').loc[:,'official gene symbol'][0:10]\n",
    "# print('TOP NEUTROPHIL GENES')\n",
    "# for s_gene in ls_gene:\n",
    "#     try:\n",
    "#         if (df_results.loc[df_results.gene_name == s_gene,'pvalue'] < 0.05).any():\n",
    "#             print(df_results.loc[df_results.gene_name == s_gene,['pvalue','padj','gene_name','log2FoldChange']])\n",
    "#             print(df_marker.loc[df_marker.loc[:,'official gene symbol']==s_gene,'cell type'])\n",
    "#     except:\n",
    "#         print('why')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # in lung cohort, lots of genes found in myocytes, endothelial cells, acinar, nerve, pancreatic progenitor cells\n",
    "# # in liver cohort, epithelial genes\n",
    "# for s_gene in df_results[df_results.padj<0.05].sort_values(by='log2FoldChange').gene_name:\n",
    "#     df_gene= df_marker[df_marker.loc[:,'official gene symbol']==s_gene]\n",
    "#     if len(df_gene) > 0:\n",
    "#         print(s_gene)\n",
    "#         print(df_results[df_results.gene_name==s_gene].log2FoldChange.values[0])\n",
    "#         print(df_gene.loc[:,'cell type'])\n",
    "#     else:\n",
    "#         continue#print(f'{s_gene} not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s_gene in df_results[df_results.padj<0.05].sort_values(by='log2FoldChange').gene_name:\n",
    "#     df_gene= df_marker2[df_marker2.loc[:,'Gene']==s_gene]\n",
    "#     if len(df_gene) > 0:\n",
    "#         print(s_gene)\n",
    "#         print(df_results[df_results.gene_name==s_gene].log2FoldChange.values[0])\n",
    "#         print(df_gene.loc[:,'Celltype (minor-lineage)'])\n",
    "#     else:\n",
    "#         continue#print(f'{s_gene} not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s_gene in df_results[df_results.padj<0.05].sort_values(by='log2FoldChange').gene_name:\n",
    "#     df_gene= df_marker3[df_marker3.loc[:,'Gene']==s_gene]\n",
    "#     if len(df_gene) > 0:\n",
    "#         print(s_gene)\n",
    "#         print(df_results[df_results.gene_name==s_gene].log2FoldChange.values[0])\n",
    "#         print(df_gene.loc[:,'Celltype (minor-lineage)'])\n",
    "#     else:\n",
    "#         continue#print(f'{s_gene} not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_matrix = pd.read_csv('DESeq2_matrix.csv',index_col=0)\n",
    "# df_matrix.index = [item.split('.')[0] for item in df_matrix.index]\n",
    "# df_matrix['Gene'] = df_matrix.index.map(dict(zip(df_gene_names.GENEID,df_gene_names.SYMBOL)))\n",
    "# df_matrix = df_matrix.set_index('Gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls_col = ['CXCR1','CXCR2','CXCL1', 'CXCL2', #also in monocyte\n",
    "#           'S100A12', 'S100A9', 'MMP8', 'ARG1','OLFM4','CD274',#immature neutrophils,immunosupressive\n",
    "#           'CXCL3', 'CXCL5', 'CXCL6',  'CXCL8','CCRL2','CEACAM8','MPO','ITGAM','CD33',#neutophils 'CXCL7',\n",
    "#            'CCR2','CCL2','CD68','CD163',#'CCL8','CCL7',#macs\n",
    "#           'CD3E','CD4','CD8A'],#'CCL21','IL2','XCL1','CCR5','CXCR3','CCR7','CCL5','CCL3','CXCL9','CXCL10','CCL21','CCL19'] # Tcell recruitment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_t = df_matrix.loc[ls_col].T\n",
    "# df_t.index.name = 'OPTR.Specimen.ID'\n",
    "# df_plot = df_cat.merge(df_t,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# for s_col in ls_col[0]:\n",
    "#     statistic, pvalue = scipy.stats.pearsonr(x=df_plot.loc[~df_plot.pORG_Primary.isna(),'pORG_Primary'],\n",
    "#                                           y=df_plot.loc[~df_plot.pORG_Primary.isna(),s_col])\n",
    "#     if pvalue < 0.05:\n",
    "#         print(s_col)\n",
    "#         fig, ax = plt.subplots()\n",
    "#         sns.regplot(data=df_plot[~df_plot.pORG_Primary.isna()],x='pORG_Primary',y=s_col)\n",
    "#         ax.set_title(f'{s_col} r={statistic:.2} p={pvalue:.2}')                                      \n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls_compare = ['CD3E','CD4','CD68','CD8A'] #'CD3D','CD3G','GZMB','MS4A1'\n",
    "# df_filter = df_filter.set_index('SpecimenID')\n",
    "# df_compare = df_plot[~df_plot.pORG_Primary.isna()].loc[:,ls_compare].merge(df_filter.loc[:,ls_compare],left_index=True,\n",
    "#                         right_index=True, suffixes=('','_c'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s_col in ls_compare:\n",
    "#     statistic, pvalue = scipy.stats.pearsonr(x=df_compare.loc[:,s_col],\n",
    "#                                           y=df_compare.loc[:,f'{s_col}_c'])\n",
    "#     if pvalue < 0.1:\n",
    "#         print(s_col)\n",
    "#         fig, ax = plt.subplots()\n",
    "#         sns.regplot(data=df_compare,x=s_col,y=f'{s_col}_c')\n",
    "#         ax.set_title(f'{s_col} r={statistic:.2} p={pvalue:.2}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSVA <a name=\"rnagsva\"></a> \n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #\n",
    "# df_cat = pd.read_csv('20230905_Patient_Metadata_OPTR.csv',index_col=0)\n",
    "# #df_cat['Survival'] = df_cat.cVitalStatus.replace({'Alive':0,'Dead':1})\n",
    "# #df_cat['OPTR'] = np.int64(df_cat.OPTR_x)\n",
    "# print(df_cat.OPTR.dropna().duplicated().any())\n",
    "# df_cat['OPTR'] = np.int64(df_cat.OPTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # load new survival\n",
    "\n",
    "# df_new_surv = pd.read_excel('annotation/cancer_participant_overview_optr_2023-05-04_16-55-18.xlsx')#,dtype=object\n",
    "# df_surv['Participant ID'] = [item.split('-')[0] for item in df_surv.Old_Pt_ID]\n",
    "# df_new_surv.loc[:,'Participant ID'] = df_new_surv.loc[:,'Participant ID'].astype(object)\n",
    "# df_new_surv.loc[:,'OPTR'] = np.int64(df_new_surv.loc[:,'Participant ID'])\n",
    "# #define rapid recurrence\n",
    "# for s_dates in df_new_surv.columns[df_new_surv.columns.str.contains(\"Date\")]:\n",
    "#     df_new_surv[s_dates]= pd.to_datetime(df_new_surv[s_dates],yearfirst=True)\n",
    "# df_new_surv['Resection_to_Recurrence'] = df_new_surv.loc[:,'First Recurrence Date'] - df_new_surv.loc[:,'Definitive Resection Date'] #\n",
    "\n",
    "# df_new_surv['Resection_to_Progression']  = df_new_surv.loc[:,'First Progression Date'] - df_new_surv.loc[:,'Definitive Resection Date'] #- \n",
    "# b_rr = (df_new_surv['Resection_to_Recurrence'] < pd.Timedelta(\"180 days\")) & (df_new_surv.loc[:,'Type of First Recurrence']=='Distant recurrence invasive tumor,liver')\n",
    "# print(b_rr.value_counts())\n",
    "\n",
    "# b_ls = (df_new_surv['Resection_to_Recurrence'] > pd.Timedelta(\"548 days\"))#\"730 days\"\n",
    "# print(b_ls.value_counts())\n",
    "# df_new_surv.loc[b_rr,'RecurrenceState'] = 'rapid'\n",
    "# df_new_surv.loc[b_ls,'RecurrenceState'] = 'long-term'\n",
    "# print(df_new_surv.loc[:,'Participant ID'].duplicated().any())\n",
    "# df_new_surv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gsva = pd.read_csv('results/results_GSVA.csv',index_col=0)\n",
    "# df_gsva.index = [item.replace('X','').replace('.','-') for item in df_gsva.index]\n",
    "# df_gsva.rename({'neutrophil activation involved in immune response':'neut. act. invol. in imm. resp.',\n",
    "#                'T cell activation involved in immune response':'T cell act. invol. in imm. resp.'},axis=1,inplace=True)\n",
    "# df_gsva['OPTR'] = [int(item.split('-')[0]) for item in df_gsva.index]\n",
    "# df_gsva.OPTR.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls_col = ['pORG_Primary','pSUB_Primary','RecurrenceState','PurIST_Subtype','LiverVsLungOnly',\n",
    "#                        'cDays_from_Diagnosis_to_FU','cDays_from_Resection_to_Recurrence','Survival',\n",
    "#                        'HR_DDR_Alterations','BRCA_Alterations']\n",
    "# ls_col = [ #'Days from Diagnosis to FU',\n",
    "#           'OPTR',\n",
    "# #  'Days from Resection to Recurrence',\n",
    "# #  'Days from Resection to FU',\n",
    "# #  'Days from Earliest Recur to FU','Survival',\n",
    "#      'PurIST_Primary'\n",
    "#    ]\n",
    "# df_plot = df_cat.loc[:,ls_col].merge(df_gsva,on='OPTR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #df_plot = df_cat.loc[:,ls_col].merge(df_new_surv.loc[:,['RecurrenceState','OPTR']],on='OPTR')\n",
    "# df_plot = df_plot.merge(df_new_surv.loc[:,['RecurrenceState','OPTR']],on='OPTR')\n",
    "# df_plot = df_plot.replace({'NoData':np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_plot =df_plot.dropna()\n",
    "# df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls  = df_plot[df_plot.RecurrenceState.notna()].OPTR\n",
    "# print(len(ls))\n",
    "# df_cat[(df_cat.OPTR.isin(ls)) & (df_cat.PurIST_Primary_T2.notna())].OPTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_plot.loc[df_plot.OPTR==4806]\n",
    "# df_plot.RecurrenceState.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # select col\n",
    "# ls_gsva = df_gsva.columns.tolist() + ['PurIST_Primary']\n",
    "# ls_gsva =  ['HALLMARK_MYOGENESIS']#['PurIST_Met']#['HALLMARK_MYC_TARGETS_V1','HALLMARK_MYC_TARGETS_V2']\n",
    "# alpha = 1.1\n",
    "# savedir = f'{codedir}/{s_date}'\n",
    "# s_time = 'cDays_from_Diagnosis_to_FU'\n",
    "# s_censor = 'Survival' #'cVitalStatus'\n",
    "# for s_marker in ls_gsva: #df_gsva.columns[-30::]:#['response to type II interferon','type II interferon-mediated signaling pathway']:#[-28::]:#df_gsva.columns[-12:-10]: #\n",
    "#     for s_group in ['RecurrenceState']:#'RecurrenceState','PurIST_Subtype',,'LiverVsLungOnly','RecurrenceState','HR_DDR_Alterations','BRCA_Alterations'\n",
    "#         try:\n",
    "#             s_high = df_plot.loc[:,s_group].dropna().unique()[0]\n",
    "#             s_low = df_plot.loc[:,s_group].dropna().unique()[1]\n",
    "#         except:\n",
    "#             print(f'{s_marker} error')\n",
    "#             continue\n",
    "#         n_high = sum(df_plot.loc[:,s_group]==s_high)\n",
    "#         n_low = sum(df_plot.loc[:,s_group]==s_low)\n",
    "#         statistic,pvalue = stats.ttest_ind(df_plot.loc[df_plot.loc[:,s_group]==s_high,s_marker],\n",
    "#                                            df_plot.loc[df_plot.loc[:,s_group]==s_low,s_marker])\n",
    "#         #statistic,pvalue = stats.mannwhitneyu(df_plot.loc[df_plot.loc[:,s_group]==s_high,s_marker],\n",
    "#         #                                       df_plot.loc[df_plot.loc[:,s_group]==s_low,s_marker])\n",
    "#         if pvalue <= alpha:\n",
    "#             fig, ax = plt.subplots(figsize=(3.3,3),dpi=300)\n",
    "#             sns.boxplot(data=df_plot,x=s_group,y=s_marker,showfliers=False,ax=ax,order=['long-term','rapid']) #,palette=['mediumpurple','deepskyblue']\n",
    "#             sns.stripplot(data=df_plot,x=s_group,y=s_marker,ax=ax,palette='dark',order=['long-term','rapid'])#,palette=['indigo','mediumblue']\n",
    "#             ax.set_ylim(ax.get_ylim()[0],ax.get_ylim()[1])\n",
    "#             #plt_sig(df_test,ax,10)\n",
    "#             ax.set_title(f'{s_group} versus\\n {s_marker}\\np={pvalue:.4f} (n={n_low}, {n_high})')\n",
    "#             ax.set_ylabel(f'GSVA Score')\n",
    "#             plt.tight_layout()\n",
    "#             fig.savefig(f'{s_date}/boxplot_GSVA_{s_marker.replace(\" \",\"_\")}_versus_{s_group}.png')\n",
    "#             break\n",
    "            \n",
    "# #         break\n",
    "#     #break\n",
    "#     #s_plat = ''\n",
    "#     #s_subtype = f''\n",
    "#     #s_cell = 'GSVA'\n",
    "#     #for cutp in [.5,0.33,0.66]: #,0.33\n",
    "#     #    df_km_p = single_km(df_plot,s_cell,s_subtype,s_plat,s_marker,savedir,alpha,cutp,s_time,s_censor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# for s_col in ls_gsva:#df_gsva.columns[-38::]:\n",
    "#     statistic, pvalue = scipy.stats.pearsonr(x=df_plot.loc[~df_plot.pORG_Primary.isna(),'pORG_Primary'],\n",
    "#                                           y=df_plot.loc[~df_plot.pORG_Primary.isna(),s_col])\n",
    "#     if pvalue < 0.1:\n",
    "#         print(s_col)\n",
    "#         fig, ax = plt.subplots()\n",
    "#         sns.regplot(data=df_plot[~df_plot.pORG_Primary.isna()],x='pORG_Primary',y=s_col)\n",
    "#         ax.set_title(f'{s_col} r={statistic:.2} p={pvalue:.2}')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_cat['Survival'] = df_cat.cVitalStatus.replace({'Alive':0,'Dead':1})\n",
    "# alpha = 0.05\n",
    "# s_plat = ''\n",
    "# s_subtype = f''\n",
    "# s_cell = 'GSVA'\n",
    "# for s_col in ls_gsva:#df_gsva.columns:\n",
    "#     #s_col = 'HALLMARK_MYC_TARGETS_V1'\n",
    "#     statistic, pvalue = scipy.stats.pearsonr(x=df_plot.loc[~df_plot.pORG_Primary.isna(),'pORG_Primary'],\n",
    "#                                           y=df_plot.loc[~df_plot.pORG_Primary.isna(),s_col])\n",
    "#     if pvalue < 0.01:\n",
    "#         #print(s_col)\n",
    "#         fig, ax = plt.subplots()\n",
    "#         sns.regplot(data=df_plot[~df_plot.pORG_Primary.isna()],x='pORG_Primary',y=s_col)\n",
    "#         ax.set_title(f'{s_col} r={statistic:.2} p={pvalue:.2}')     \n",
    "#         s_plat = ''\n",
    "#         s_subtype = f''\n",
    "#         s_cell = 'GSVA'\n",
    "#     for cutp in [.5,0.33,0.66,.3,.6]: #,0.33\n",
    "#         df_km_p = util.single_km(df_plot,s_cell,s_subtype,s_plat,s_col,savedir,alpha,cutp,s_time,s_censor)\n",
    "#     #break\n",
    "#     #for cutp in [.5,0.33,0.66]: #,0.33\n",
    "#     #    df_km_p = single_km(df_plot,s_cell,s_subtype,s_plat,s_col,savedir,alpha,cutp,\n",
    "#     #                        s_time='cDays_from_Resection_to_Recurrence',s_censor=s_censor)\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all = df_plot.loc[:,df_plot.dtypes=='float64']\n",
    "# dim = (20,20)\n",
    "# g = sns.clustermap(df_all.corr())\n",
    "# plt.close()\n",
    "# categories_order = df_all.corr().iloc[g.dendrogram_col.reordered_ind,:].index.tolist()\n",
    "# df_all = df_all.loc[:,categories_order]\n",
    "# rho = df_all.corr()\n",
    "# pval = df_all.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "# p_vals = pval.applymap(lambda x: ''.join(['*' for t in [0.05] if x<=t])) #0.001,0.005,\n",
    "# fig, ax = plt.subplots(figsize=dim,dpi=300)\n",
    "# sns.heatmap(df_all.corr(), vmin=-1, vmax=1, annot=p_vals, fmt = '', cmap='RdBu_r',ax=ax,yticklabels=1,xticklabels=1)\n",
    "# #ax.set_title(f'Fraction Cell Type in {s_compartment} Correlation', fontdict={'fontsize':16}, pad=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TCRseq analysis <a name=\"tcr\"></a> \n",
    "\n",
    "\n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "df_cat = pd.read_excel('Supplemental_Data/Supplemental_Dataset_1.xlsx',sheet_name=0,\n",
    "                          index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_tcr = ['Tumor_RearrangementDetails_05-25-2023_5-19-54_PM.tsv',\n",
    "          'Blood1_RearrangementDetails_05-25-2023_5-38-47_PM.tsv',\n",
    "          'Blood2_RearrangementDetails_05-25-2023_5-52-58_PM.tsv',\n",
    "         'Mets_RearrangementDetails_05-25-2023_5-59-08_PM.tsv']\n",
    "df_tcr_all = pd.DataFrame()\n",
    "for s_tcr in ls_tcr:\n",
    "    print(s_tcr)\n",
    "    df_tcr = pd.read_csv(f'../TCR/{s_tcr}',sep='\\t')#,index_col=0\n",
    "    df_tcr_all = pd.concat([df_tcr_all,df_tcr])\n",
    "    #break\n",
    "# drop blood collected before diagnosis\n",
    "df_tcr_all = df_tcr_all[df_tcr_all.sample_name!='ST-00021096-B'].copy()\n",
    "\n",
    "df_tcr_all['Public_Patient_ID'] = ['ST-' + item.split('-')[1] for item in df_tcr_all.sample_name]\n",
    "print(df_tcr_all.sample_name.nunique())\n",
    "288 + 174 + 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test = df_tcr_all.groupby('sample_name').sum(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.sort_values(by='templates')\n",
    "# df_test.loc['ST-00021096-B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set([item[0:-2] for item in df_test[df_test.index.str.contains('-B')].index]) - es_pt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge = pd.read_csv('Supplemental_Data/Supplemental_Dataset_8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es_pt_ = set(df_merge[df_merge.Clonality_Blood.notna()].Public_Patient_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #look at total productive templates in the tumor and blood\n",
    "# df_tcr_all[df_tcr_all.sample_name.str.contains('-B')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate shared/ clonal sequences\n",
    "\n",
    "Done\n",
    "\n",
    "For shared, clonal sequences within cohorts, the top 50 rearrangements (by frequency in each sample) were \n",
    "compiled for all samples, and the Immunoseq Sequence Search Tool was used to identify all samples in the\n",
    "cohort that contained any of those CDR3b sequences at any frequency. Only the CDR3b amino acid sequences \n",
    "found in at least 25% of samples in the cohort were considered shared, clonal sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # For shared, clonal sequences within cohorts, the top 50 rearrangements (by frequency in each sample) were \n",
    "# # compiled for all samples, and the Immunoseq Sequence Search Tool was used to identify all samples in the\n",
    "# # cohort that contained any of those CDR3b sequences at any frequency. Only the CDR3b amino acid sequences \n",
    "# # found in at least 25% of samples in the cohort were considered shared, clonal sequences. \n",
    "# ls_un = df_tcr_all.sample_name.unique()\n",
    "# d_top50 = {}\n",
    "# print(len(ls_un))\n",
    "# for idx, s_sample in enumerate(ls_un):\n",
    "#     print(f'{idx} {s_sample}')\n",
    "#     df_sample = df_tcr_all.loc[(df_tcr_all.sample_name==s_sample)]\n",
    "#     es_sample = set(df_sample.sort_values(by='productive_frequency',ascending=False)[0:50].amino_acid)\n",
    "#     d_top50.update({s_sample:es_sample})\n",
    "    \n",
    "# #save\n",
    "# d_top50_ls = {}\n",
    "# for key, item in d_top50.items():\n",
    "#     d_top50_ls.update({key:list(item)})\n",
    "\n",
    "# import json\n",
    "# with open(\"TCRtop50.json\", \"w\") as outfile:\n",
    "#     json.dump(d_top50_ls, outfile)\n",
    "\n",
    "# #need to figure out which are in 25% of cohort... samples ... tumor .. blood\n",
    "# #load...\n",
    "# import json\n",
    " \n",
    "# # Opening JSON file\n",
    "# with open('TCRtop50.json', 'r') as openfile:\n",
    " \n",
    "#     # Reading from json file\n",
    "#     d_top50 = json.load(openfile)\n",
    "\n",
    "# es_top50 = set()\n",
    "# for key, item in d_top50.items():\n",
    "#     es_top50 = es_top50.union(item)\n",
    "\n",
    "# # add cohorts\n",
    "# df6 = pd.read_excel('./MethodsAndReferencesSupplementalData/SupplementalDataset6.xlsx',sheet_name=None)\n",
    "# for s_sheet in ['Tumor Samples','Blood Samples']:\n",
    "#     df6[s_sheet].loc[df6[s_sheet].loc[:,'Lung Met Present in Patient'] == 'YES','Cohort'] = 'Lung'\n",
    "#     df6[s_sheet].loc[df6[s_sheet].loc[:,'Liver Met Present in Patient'] == 'YES','Cohort'] = 'Liver'\n",
    "#     print(df6[s_sheet]['Cohort'].value_counts())\n",
    "#     d_cohort = dict(zip(df6[s_sheet].loc[:,'Patient ID'],df6[s_sheet].loc[:,'Cohort']))\n",
    "#     if s_sheet == 'Blood Samples':\n",
    "#         b_sample = df_tcr_all.sample_name.str.contains('-B')\n",
    "#     else:\n",
    "#         b_sample = ~df_tcr_all.sample_name.str.contains('-B')\n",
    "#     df_tcr_all.loc[b_sample,'Cohort'] = df_tcr_all.loc[b_sample].Public_Patient_ID.map(d_cohort)\n",
    "#     #break\n",
    "\n",
    "# #tumor\n",
    "# df_tcr_all.loc[~df_tcr_all.sample_name.str.contains('-B'),'Site'] = 'Tumor'\n",
    "# #blood\n",
    "# df_tcr_all.loc[df_tcr_all.sample_name.str.contains('-B'),'Site'] = 'Blood'\n",
    "# df_tcr_all['CohortSite'] = df_tcr_all.Cohort + '.' + df_tcr_all.Site \n",
    "# d_shared_clonal = {}\n",
    "# ls_percent = [0.05,0.1,0.25]\n",
    "# ls_group = ['Cohort','Site','CohortSite']\n",
    "# for i_percent in ls_percent:\n",
    "#     for s_group in ls_group:\n",
    "#         for s_cohort in df_tcr_all.loc[:,s_group].dropna().unique():\n",
    "#             print(s_cohort)\n",
    "#             df_cohort = df_tcr_all[df_tcr_all.loc[:,s_group]==s_cohort]\n",
    "#             df_test = df_cohort[df_cohort.amino_acid.isin(es_top50)]\n",
    "#             es_shared = df_test.groupby('amino_acid').Public_Patient_ID.nunique().sort_values(ascending=False)\n",
    "#             i_thresh = df_cohort.Public_Patient_ID.nunique()*i_percent\n",
    "#             ls_shared = es_shared[es_shared>i_thresh].index.tolist()\n",
    "#             s_label = f'{s_group}_{s_cohort}_{i_percent}'\n",
    "#             d_shared_clonal.update({s_label:ls_shared})\n",
    "# d_shared_clonal.keys()\n",
    "# import json\n",
    "# with open(\"TCR_shared_clonal.json\", \"w\") as outfile:\n",
    "#     json.dump(d_shared_clonal, outfile)\n",
    "    \n",
    "# # Opening JSON file\n",
    "# with open('TCR_shared_clonal.json', 'r') as openfile:\n",
    " \n",
    "#     # Reading from json file\n",
    "#     json_object = json.load(openfile)\n",
    "\n",
    "\n",
    "# df_distinct = pd.DataFrame()\n",
    "# for idx, s_sample in enumerate(ls_un):\n",
    "#     print(f'{idx} {s_sample}')\n",
    "#     df_sample = df_tcr_all.loc[(df_tcr_all.sample_name==s_sample)]\n",
    "#     i_unique = df_sample[df_sample.amino_acid.isin(es_top50)].amino_acid.nunique()\n",
    "#     i_total = df_sample.amino_acid.nunique()\n",
    "#     df_distinct.loc[s_sample,'Number_Top_50'] = i_unique\n",
    "#     df_distinct.loc[s_sample,'Total_Unique_TCRs'] = i_total\n",
    "#     for key, item in d_shared_clonal.items():\n",
    "#         i_unique = df_sample[df_sample.amino_acid.isin(item)].amino_acid.nunique()\n",
    "#         df_distinct.loc[s_sample,f'{key}_nunique'] = i_unique\n",
    "#         #break\n",
    "#     #break\n",
    "# df_distinct.to_csv(f'Liver_Lung_PDAC/TCR_Shared_Clonal_by_Cohort.csv')\n",
    "\n",
    "# df_distinct = pd.DataFrame()\n",
    "# for idx, s_sample in enumerate(ls_un):\n",
    "#     print(f'{idx} {s_sample}')\n",
    "#     df_sample = df_tcr_all.loc[(df_tcr_all.sample_name==s_sample)]\n",
    "#     i_unique = df_sample[df_sample.amino_acid.isin(es_top50)].amino_acid.nunique()\n",
    "#     i_total = df_sample.amino_acid.nunique()\n",
    "#     df_distinct.loc[s_sample,'Number_Top_50'] = i_unique\n",
    "#     df_distinct.loc[s_sample,'Total_Unique_TCRs'] = i_total\n",
    "#     for key, item in d_shared_clonal.items():\n",
    "#         i_unique = df_sample[df_sample.amino_acid.isin(item)].amino_acid.nunique()\n",
    "#         df_distinct.loc[s_sample,f'{key}_nunique'] = i_unique\n",
    "#         #break\n",
    "#     #break\n",
    "# df_distinct.to_csv(f'Liver_Lung_PDAC/TCR_Shared_Clonal_by_Cohort.csv')\n",
    "\n",
    "# #use jasons clones\n",
    "# ls_un = df_tcr_all.sample_name.unique()\n",
    "# for s_cohort in df6['Shared, Clonal Seqs'].Cohort.unique():\n",
    "#     print(s_cohort)\n",
    "#     es_top50 = set(df6['Shared, Clonal Seqs'][df6['Shared, Clonal Seqs'].Cohort==s_cohort].loc[:,'TCRB CDR3 Amino Acid Sequence'])\n",
    "#     df_distinct = pd.DataFrame()\n",
    "#     for idx, s_sample in enumerate(ls_un):\n",
    "#         print(f'{idx} {s_sample}')\n",
    "#         df_sample = df_tcr_all.loc[(df_tcr_all.sample_name==s_sample)]\n",
    "#         i_unique = df_sample[df_sample.amino_acid.isin(es_top50)].amino_acid.nunique()\n",
    "#         i_total = df_sample.amino_acid.nunique()\n",
    "#         df_distinct.loc[s_sample,'Number_Shared_Clonal'] = i_unique\n",
    "#         df_distinct.loc[s_sample,'Total_Unique_TCRs'] = i_total\n",
    "# #         for key, item in d_shared_clonal.items():\n",
    "# #             i_unique = df_sample[df_sample.amino_acid.isin(item)].amino_acid.nunique()\n",
    "# #             df_distinct.loc[s_sample,f'{key}_nunique'] = i_unique\n",
    "# #             break\n",
    "#         #break\n",
    "#     df_distinct.to_csv(f'Liver_Lung_PDAC/TCR_Shared_Clonal_by_{s_cohort.replace(\"/\",\".\")}.csv')\n",
    "\n",
    "# #look at productive freq\n",
    "# df_distinct = pd.DataFrame(index=ls_un)\n",
    "# for s_seq in df6['Shared, Clonal Seqs'].loc[:,'TCRB CDR3 Amino Acid Sequence'].unique():\n",
    "#     se_seq = df_tcr_all[df_tcr_all.amino_acid==(s_seq)].groupby('sample_name').productive_frequency.sum()\n",
    "#     df_distinct[s_seq] = df_distinct.index.map(se_seq).fillna(0)\n",
    "# df_distinct.to_csv(f'Liver_Lung_PDAC/TCR_Shared_Clonal_Productive_Freq.csv')\n",
    "# df_distinct.mean()\n",
    "\n",
    "# # Opening JSON file\n",
    "# with open('TCR_shared_clonal.json', 'r') as openfile:\n",
    "#     # Reading from json file\n",
    "#     json_object = json.load(openfile)\n",
    "\n",
    "# for s_key, ls_seq in json_object.items():\n",
    "#     print(s_key)\n",
    "#     df_distinct = pd.DataFrame(index=ls_un)\n",
    "#     for s_seq in ls_seq:\n",
    "#         se_seq = df_tcr_all[df_tcr_all.amino_acid==(s_seq)].groupby('sample_name').productive_frequency.sum()\n",
    "#         df_distinct[s_seq] = df_distinct.index.map(se_seq).fillna(0)\n",
    "#     df_distinct.to_csv(f'Liver_Lung_PDAC/TCR_Shared_Clonal_{s_key}_Productive_Freq.csv')\n",
    "\n",
    "# show rosie what the data look like\n",
    "# df_test = df_tcr_all[df_tcr_all.sample_name=='ST-00017310-T']\n",
    "# df_test.amino_acid.nunique()\n",
    "# df_test.rearrangement.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared, Clonal Plots\n",
    "For shared, clonal sequences within cohorts, the top 50 rearrangements (by frequency in each\n",
    "sample) were compiled for all samples, and the Immunoseq Sequence Search Tool was used to\n",
    "identify all samples in the cohort that contained any of those CDR3 sequences at any frequency.\n",
    "Only the CDR3 amino sequences found in at least 25% of samples in the cohort were considered\n",
    "shared, clonal sequences.\n",
    "\n",
    "\n",
    "We found similar numbers of these shared, clonal\n",
    "CDR3β sequences in liver-cohort tumors (N=21) as in lung-cohort tumors (N=24); in contrast, we\n",
    "found many more shared, clonal CDR3β sequences among blood samples from patients in the\n",
    "liver cohort (N=174) than from patients in the lung cohort (N=41, Figure 6B). \n",
    "**how is this normalized?**\n",
    "\n",
    "\n",
    "We examined the frequencies of the shared, clonal responses and\n",
    "found that in lung-cohort tumors they existed at higher frequencies than in liver-cohort tumors\n",
    "(Figure 6C), in contrast to what we found for responses to putative mutant KRAS-specific tumor-\n",
    "initiating epitopes. These results suggest that liver-cohort tumors may promote clonal responses\n",
    "against persistent neoepitopes (Figure 6A), whereas lung-cohort tumors may be more likely to\n",
    "develop shared, clonal responses against new (though uncharacterized) tumor antigens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df_shared_je = pd.read_csv(f'TCR/TCR_Shared_Clonal_by_Cohort.csv',index_col=0)\n",
    "\n",
    "#add the patient ID \n",
    "\n",
    "df_shared_je['Public_Patient_ID'] = ['ST-' + item.split('-')[1] for item in df_shared_je.index]\n",
    "\n",
    "#load up supplemental data 6: shared clonal\n",
    "#df6 = pd.read_excel('../MethodsAndReferencesSupplementalData/SupplementalDataset6.xlsx',sheet_name=None)\n",
    "df6 = pd.read_excel('Supplemental_Data/Supplemental_Dataset_9.xlsx',sheet_name=None)#Supplemental_Dataset_9.xlsx\n",
    "#df6.keys()\n",
    "es_shared = set(df6['Shared, Clonal Seqs'].loc[:,'TCRB CDR3 Amino Acid Sequence'])\n",
    "print(len(es_shared))\n",
    "print(df6['Shared, Clonal Seqs'].Cohort.value_counts())\n",
    "df_tcr_all['Public_Patient_ID'] = ['ST-' + item.split('-')[1] for item in df_tcr_all.sample_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # old/ not used\n",
    "# importlib.reload(util)\n",
    "# pal_liv_r = ('#D55E00','#0072B2',)\n",
    "# sns.set_palette(pal_liv_r)\n",
    "# x='Cohort'\n",
    "# ls_col = ['Percentage of Samples Containing',\n",
    "#           'Average Frequency',\n",
    "#               #'Sum of Frequencies',\n",
    "#               'Average Frequency\\n(among samples with sequence)']\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "#     for s_site in ['Tumor','Blood','All']:\n",
    "#         if s_site == 'All':\n",
    "#             df = df6['Shared, Clonal Seqs'].copy()\n",
    "#         else:\n",
    "#             df = df6['Shared, Clonal Seqs'].loc[df6['Shared, Clonal Seqs'].Cohort.str.contains(s_site)].copy()\n",
    "#         df['Average Frequency'] = df['Sum of Frequencies']/df['Number in Cohort']\n",
    "#         df['Percentage of Samples Containing'] = df['Present In']/df['Number in Cohort']\n",
    "#         for s_col in ls_col:\n",
    "#             ls_groups = sorted(df.loc[:,x].dropna().unique())\n",
    "#             print(sorted(df.loc[:,x].dropna().value_counts()))\n",
    "#             plotting = {\"data\": df,\"x\": x,\"y\":s_col,\"order\":ls_groups}\n",
    "#             fig, ax, test_results = util.annotated_stripplot(plotting,ls_groups,b_correct=False,figsize=(3,3))\n",
    "#             ax.set_title(f'{s_site}')\n",
    "#             #ax.legend(bbox_to_anchor=(1,1))\n",
    "#             break\n",
    "#         break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# barplot not used\n",
    "# #not normalizeb by no. patients\n",
    "# df_shared = df6['Shared, Clonal Seqs'].groupby('Reported Specific for Infectious Agent').Cohort.value_counts()#.reset_index()\n",
    "# df_shared.name = 'No.'\n",
    "# df_shared = df_shared.reset_index(drop=False)\n",
    "# x=df_shared.Cohort.unique()\n",
    "# y1=df_shared.loc[df_shared.loc[:,'Reported Specific for Infectious Agent']=='YES','No.']\n",
    "# y2=df_shared.loc[df_shared.loc[:,'Reported Specific for Infectious Agent']=='NO','No.']\n",
    "# plt.bar(x, y1, color='r')\n",
    "# plt.bar(x, y2, bottom=y1, color='k')\n",
    "# plt.ylabel('No.')\n",
    "# plt.title('not normalized')\n",
    "# #plt.close()\n",
    "# # fig, ax =plt.subplots()\n",
    "# # sns.barplot(data=df_shared, x='Cohort', y='No.', hue='Reported Specific for Infectious Agent',dodge=True,ax=ax)\n",
    "# # ax.set_title('not normalized')\n",
    "# #add porg quartiles, cohorts, to tcr data\n",
    "# for s_porg in ['pORG_0.2_All_quartiles','pORG_0.2_Primary_quartiles', 'pORG_0.2_Met_quartiles']:\n",
    "#     d_score = dict(zip(df_patient.Public_Patient_ID,df_patient.loc[:,s_porg]))\n",
    "#     df_tcr_all[s_porg] = df_tcr_all.Public_Patient_ID.map(d_score)\n",
    "# for s_site, d_cohort in dd_cohort.items():\n",
    "#     df_tcr_all[f'{s_site}_Cohort'] = df_tcr_all.Public_Patient_ID.map(d_cohort)\n",
    "    \n",
    "# ls_groups = ['pORG_0.2_All_quartiles','pORG_0.2_Primary_quartiles', 'pORG_0.2_Met_quartiles',\n",
    "#             'Tumor_Cohort','Blood_Cohort']\n",
    "# # calculate percentage of samples containing\n",
    "\n",
    "# for s_cohort in df6['Shared, Clonal Seqs'].Cohort.unique():\n",
    "#     df = df6['Shared, Clonal Seqs'][df6['Shared, Clonal Seqs'].Cohort==s_cohort]\n",
    "#     es_seq = set(df.loc[:,'TCRB CDR3 Amino Acid Sequence'])\n",
    "#     df_tcr_in = df_tcr_all[df_tcr_all.amino_acid.isin(es_seq)]\n",
    "#     break\n",
    "# ls_groups = ['pORG_0.2_All_quartiles','pORG_0.2_Primary_quartiles', 'pORG_0.2_Met_quartiles',\n",
    "#             'Tumor_Cohort','Blood_Cohort']\n",
    "# for s_group in ls_groups:\n",
    "#     se_in = df_tcr_in.groupby(s_group).Public_Patient_ID.nunique()\n",
    "#     break\n",
    "    \n",
    "    \n",
    "# barplot not used\n",
    "# # 6B\n",
    "# #normalized by no patients\n",
    "# d_counts = {'Liver/Blood':76,'Lung/Blood':16,'Liver/Tumor':59,'Lung/Tumor':16}\n",
    "# for s_cohort in df_shared.Cohort.unique():\n",
    "#     df_shared.loc[df_shared.Cohort==s_cohort,'No. per Pt.'] = df_shared.loc[df_shared.Cohort==s_cohort,'No.']/d_counts[s_cohort]\n",
    "# x=df_shared.Cohort.unique()\n",
    "# y1=df_shared.loc[df_shared.loc[:,'Reported Specific for Infectious Agent']=='YES','No. per Pt.']\n",
    "# y2=df_shared.loc[df_shared.loc[:,'Reported Specific for Infectious Agent']=='NO','No. per Pt.']\n",
    "# plt.bar(x, y1, color='r')\n",
    "# plt.bar(x, y2, bottom=y1, color='k')\n",
    "# plt.ylabel('No. per Pt.')\n",
    "# fig, ax =plt.subplots()\n",
    "# sns.barplot(data=df_shared, x='Cohort', y='No. per Pt.', hue='Reported Specific for Infectious Agent',dodge=True,ax=ax)\n",
    "\n",
    "# for s_site in ['Blood','Tumor']:\n",
    "#     y= 'No.'#'No. per Pt.'\n",
    "#     fig, ax = plt.subplots(dpi=300, figsize=(2.2,2))\n",
    "#     df = df_shared.groupby('Cohort').sum().reset_index()\n",
    "#     sns.barplot(data=df[df.Cohort.str.contains(s_site)],x='Cohort', y=y,color='k')\n",
    "#     ax.set_title('Number of Shared/Clonal\\nSequences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# per patient shared/clonal  <a name=\"sharedclonal\"></a> \n",
    "\n",
    "\n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df_patient = pd.read_csv('Supplemental_Data/Supplemental_Dataset_8.csv',\n",
    "                          index_col=0)\n",
    "ls_kras =['CASGDTGGYEQYF','CASKVYGYTF','CASRIGNTGELFF','CASRNLGDTQYF','CASRQGNTGELFF','CASSDPGTEAFF',\n",
    " 'CASSDSRGSQDTQYF','CASSFGQSSTYGYTF','CASSGAEGAYEQYF','CASSGLTYTDTQYF', 'CASSLEGTVEETLYF','CASSLGEGRVDGYTF',\n",
    " 'CASSLGQTNYGYTF','CASSLGRASNQPQHF','CASSLSFRQGLREQYF','CASSPGTENSPLHF','CASSQDVTSEWVDTIYF','CASSQGNTGELFF',\n",
    " 'CASSQWGGGQDTQYF','CASSSRVNQDTQYF','CASSVAGGGQETQY'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# jason's clones\n",
    "#are any shared clonal KRAS?\n",
    "%matplotlib inline\n",
    "df_sc_pt = pd.read_csv(f'TCR/TCR_Shared_Clonal_Productive_Freq.csv',index_col=0) #jason's\n",
    "print(df_sc_pt.columns.isin(ls_kras).any())\n",
    "importlib.reload(util)\n",
    "pal_porg_r = ('#E69F00','#56B4E9',)\n",
    "pal_liv_r = ('#D55E00','#0072B2',)\n",
    "sns.set_palette(pal_liv_r)\n",
    "# try - combine the liver and lung\n",
    "\n",
    "dd_cohort = {}\n",
    "\n",
    "for s_sheet in ['Tumor_Type','Blood_Type']:\n",
    "      b_type = df_patient.loc[:,s_sheet].notna()\n",
    "      d_cohort = dict(zip(df_patient.loc[b_type,'Public_Patient_ID'],df_patient.loc[b_type,'Cohort']))\n",
    "      dd_cohort.update({s_sheet.split('_')[0]:d_cohort})\n",
    "df_sc = df6['Shared, Clonal Seqs'].iloc[:,0:4].copy().rename({'TCRB CDR3 Amino Acid Sequence':'Sequence'},axis=1)\n",
    "df_sc = df_sc.merge(df_sc_pt.T.reset_index().rename({'index':'Sequence'},axis=1),on='Sequence',how='left')\n",
    "ls_cohort = [#'/Blood','/Tumor',\n",
    "            # 'Liver/Blood', 'Lung/Blood', \n",
    "    'Lung/Tumor',\n",
    "    'Liver/Tumor', \n",
    "            ]\n",
    "df_out = pd.DataFrame()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    for s_porg in ['pORG_All_quartiles','pORG_Met_quartiles','pORG_Primary_quartiles',]: #\n",
    "        for s_cohort in ls_cohort:\n",
    "            s_site = s_cohort.split('/')[1]\n",
    "            if s_site == 'Tumor':\n",
    "                df = df_sc.loc[df_sc.Cohort.str.contains(s_cohort),~df_sc.columns.str.contains('-B')].T\n",
    "                df.drop(['Cohort', 'Sequence', 'Reported Specific for Infectious Agent','Sum of Frequencies'],inplace=True)\n",
    "                if s_porg == 'pORG_Primary_quartiles':\n",
    "                    df = df_sc.loc[df_sc.Cohort.str.contains(s_cohort),df_sc.columns.str.contains('-T')].T\n",
    "                    ls_pt = df_patient.loc[df_patient.Tumor_Type=='Primary','Public_Patient_ID']\n",
    "                elif s_porg == 'pORG_Met_quartiles':\n",
    "                    df = df_sc.loc[df_sc.Cohort.str.contains(s_cohort),df_sc.columns.str.contains('-M')].T\n",
    "                    ls_pt = df_patient.loc[df_patient.Tumor_Type=='Met','Public_Patient_ID']\n",
    "                else:\n",
    "                    ls_pt = df_patient.loc[df_patient.Tumor_Type.notna(),'Public_Patient_ID']\n",
    "            elif s_site == 'Blood':\n",
    "                df = df_sc.loc[df_sc.Cohort.str.contains(s_cohort),df_sc.columns.str.contains('-B')].T\n",
    "                ls_pt = df_patient.loc[df_patient.Blood_Type.notna(),'Public_Patient_ID']\n",
    "            df = df.astype('float64')\n",
    "            print(set([item.split('-')[-1] for item in df.index]))\n",
    "            df.index = ['ST-' + item.split('-')[1] for item in df.index]\n",
    "            df['Shared/Clonal No. per Pt.'] = (df.loc[:,df.dtypes=='float64'] > 0).sum(axis=1)\n",
    "            df['Shared/Clonal Freq per Pt'] = df.drop('Shared/Clonal No. per Pt.',axis=1).sum(axis=1)\n",
    "            df['Shared/Clonal No.'] = (df.drop('Shared/Clonal No. per Pt.',axis=1) > 0).sum(axis=1) - 1\n",
    "            df['Cohort'] = df.index.map(dd_cohort[s_site])\n",
    "            df['Cohort'] = df['Cohort'].replace({'nan':pd.NA})\n",
    "            df['Public_Patient_ID'] = ['ST-' + item.split('-')[1] for item in df.index]\n",
    "            s_primary_met =  s_porg.split('pORG_')[1].split('_quartiles')[0]\n",
    "            d_score = dict(zip(df_patient.Public_Patient_ID,df_patient.loc[:,s_porg]))\n",
    "            df[s_porg] = df.Public_Patient_ID.map(d_score)\n",
    "            #'''\n",
    "            for x in ['Cohort',s_porg,]:\n",
    "                if x == 'Cohort':\n",
    "                    sns.set_palette(pal_liv_r)\n",
    "                else:\n",
    "                    sns.set_palette(pal_porg_r)\n",
    "                for s_col in ['Shared/Clonal Freq per Pt','Shared/Clonal No. per Pt.',]:#,\n",
    "                    #s_col= #'Shared/Clonal Freq' #'Shared/Clonal No.'#'Shared/Clonal Freq' #,'Shared/Clonal No.'\n",
    "                    df_plot = df.loc[df.index.isin(ls_pt)]\n",
    "                    ls_groups = sorted(df_plot.loc[:,x].dropna().unique())\n",
    "                    print(sorted(df_plot.loc[:,x].dropna().value_counts()))\n",
    "                    plotting = {\"data\": df_plot.loc[:,[x,s_col]].dropna(),\"x\": x,\"y\":s_col,\"order\":ls_groups}\n",
    "                    fig, ax, test_results = util.annotated_stripplot(plotting,ls_groups,b_correct=False)\n",
    "                    ax.set_title(f\"From: {s_cohort.replace('/',' ')}s\")\n",
    "                    ax.set_xlabel(f\"{x.replace('_0.2_',' ').replace('_',' ')}\")\n",
    "                    ax.set_ylabel(f\"{s_col.replace('/',' ')}\")\n",
    "                    ax.legend(bbox_to_anchor=(1,1)).remove()\n",
    "                    # if not (np.array([res.data.pvalue for res in test_results]) < 0.1).any():\n",
    "                    #     plt.close()\n",
    "                    ax.text(x=-0.1, y=-0.1, s='In:',transform=ax.transAxes)\n",
    "                    plt.tight_layout()\n",
    "                    fig.savefig(f\"figures/Shared_clonal_from_{s_cohort.replace('/','_')}_in_{x}_{s_col.replace('/','_')}_{s_porg.split('_')[1]}.pdf\",dpi=300)\n",
    "                    df_test = df_plot.loc[:,[x,s_col]].dropna().copy()\n",
    "                    df_test['From'] = s_cohort\n",
    "                    df_out =pd.concat([df_out,df_test]) \n",
    "                    #break #col\n",
    "                #break #in cohort or quartiles#'''\n",
    "            break #cohort (from)\n",
    "        break #pORG (pri/met/all)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(s_cohort.split(\"/\")[0])\n",
    "# ls_col = ['Public_Patient_ID','Shared/Clonal No. per Pt.','Shared/Clonal Freq per Pt',\n",
    "#          'Cohort','pORG_All_quartiles']\n",
    "# df.loc[:,ls_col].to_csv(f'Source_Extended_Data_Fig6_F_G_from{s_cohort.split(\"/\")[0]}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_out.to_csv(f'Source_Extended_Data_Figure9_H-I.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #s_porg.split('_')#[2]\n",
    "# #d_fig_6 = {}#\n",
    "# print(d_fig_6.keys())\n",
    "# #util.open_write_excel(d_fig_6,filename='Source_Data_Figure6.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ## calculate percent containing, jason's clones\n",
    "# #add porg quartiles, cohorts, to patinet data\n",
    "# df_sc_pt['Public_Patient_ID'] = ['ST-' + item.split('-')[1] for item in df_sc_pt.index]\n",
    "# df_sc_seq = df6['Shared, Clonal Seqs'].iloc[:,0:4].copy().rename({'TCRB CDR3 Amino Acid Sequence':'Sequence'},axis=1)\n",
    "\n",
    "# dd_score = {}\n",
    "# for s_porg in ['pORG_0.2_All_quartiles','pORG_0.2_Primary_quartiles', 'pORG_0.2_Met_quartiles']:\n",
    "#     d_score = dict(zip(df_patient.Public_Patient_ID,df_patient.loc[:,s_porg]))\n",
    "#     dd_score.update({s_porg:d_score})\n",
    "# for s_sheet in ['Tumor Samples','Blood Samples']:\n",
    "#     df6[s_sheet].loc[df6[s_sheet].loc[:,'Lung Met Present in Patient'] == 'YES','Cohort'] = 'Lung'\n",
    "#     df6[s_sheet].loc[df6[s_sheet].loc[:,'Liver Met Present in Patient'] == 'YES','Cohort'] = 'Liver'\n",
    "#     d_cohort = dict(zip(df6[s_sheet].loc[:,'Patient ID'],df6[s_sheet].loc[:,'Cohort']))\n",
    "#     dd_score.update({s_sheet.replace(' Samples','_Cohort'):d_cohort})\n",
    "# for s_key, d_item in dd_score.items():\n",
    "#     df_sc_pt[s_key] = df_sc_pt.Public_Patient_ID.map(d_item)\n",
    "    \n",
    "# for s_index in df_sc_seq.index:\n",
    "#     s_seq = df_sc_seq.loc[s_index,'Sequence']\n",
    "#     for s_key in dd_score.keys():\n",
    "#         df = df_sc_pt.loc[df_sc_pt.loc[:,s_key].notna(),[s_key,s_seq]].copy()\n",
    "#         df['Contains'] = df[s_seq] > 0\n",
    "#         try:\n",
    "#             d_result = dict(df.groupby(s_key).Contains.value_counts(normalize=True).loc[:,True])\n",
    "#         except:\n",
    "#             d_result = dict(zip(df.loc[:,s_key].unique(),[0,0]))\n",
    "#         for column, value in d_result.items():\n",
    "#             df_sc_seq.loc[s_index, f'{s_key}_{column}'] = value\n",
    "# ## plot percent containing, jason's clones\n",
    "# # does not match figure 6D\n",
    "# ls_cohort = [\n",
    "#              #'Liver/Blood', 'Lung/Blood',\n",
    "#     'Liver/Tumor', 'Lung/Tumor'\n",
    "#             ]\n",
    "# ls_col = ['pORG_0.2_All_quartiles_high',\n",
    "#        'pORG_0.2_All_quartiles_low', \n",
    "#           #'Tumor_Cohort_Liver', 'Tumor_Cohort_Lung',\n",
    "#     # 'pORG_0.2_Primary_quartiles_high',\n",
    "#     #    'pORG_0.2_Primary_quartiles_low', 'pORG_0.2_Met_quartiles_high',\n",
    "#       # 'pORG_0.2_Met_quartiles_low'\n",
    "#          ]\n",
    "# # ls_col = [\n",
    "# #        #'Blood_Cohort_Liver', 'Blood_Cohort_Lung'\n",
    "# #          ]\n",
    "# for s_cohort in ls_cohort:\n",
    "#     df = df_sc_seq[df_sc_seq.Cohort==s_cohort]\n",
    "#     df_plot = df.loc[:,ls_col].unstack().reset_index().rename({'level_0':'Group',\n",
    "#                                                 0:'Percentage of Samples Containing'},axis=1)\n",
    "#     plotting = {\"data\": df_plot,\"x\": 'Group',\n",
    "#                 \"y\":'Percentage of Samples Containing',\n",
    "#                 \"order\":ls_col}\n",
    "#     fig, ax, test_results = annotated_stripplot(plotting,ls_col,'shared/clonal seq')\n",
    "#     ax.set_title(f'From: {s_cohort}')\n",
    "#     ax.set_xticklabels([item.replace('_Cohort_',' ').replace('_quartiles_','\\n').replace('_0.2_',' ') for item in ls_col])\n",
    "#     ax.legend(bbox_to_anchor=(1,1))\n",
    "#     #ax.set_ylim(0,1.3)\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add high and low pORG, need to use less cohort-specicic clones\n",
    "# use all tumor, all blood instead of liver lung blood and tumor\n",
    "\n",
    "#df_patient =  pd.read_csv('annotation/20231012_Patient_Metadata_TCR_Metrics.csv',index_col = 0)\n",
    "ls_file = [ #'TCR_Shared_Clonal_Site_Blood_0.05_Productive_Freq.csv',\n",
    " #'TCR_Shared_Clonal_Site_Blood_0.1_Productive_Freq.csv',\n",
    " #'TCR_Shared_Clonal_Site_Blood_0.25_Productive_Freq.csv',\n",
    " #'TCR_Shared_Clonal_Site_Tumor_0.05_Productive_Freq.csv',\n",
    " #'TCR_Shared_Clonal_Site_Tumor_0.1_Productive_Freq.csv',\n",
    " 'TCR_Shared_Clonal_Site_Tumor_0.25_Productive_Freq.csv',]\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    for s_file in ls_file:\n",
    "        df_sc_pt = pd.read_csv(f'TCR/{s_file}',index_col=0) #JE\n",
    "        print('any KRAS?')\n",
    "        print(df_sc_pt.columns.isin(ls_kras).any())\n",
    "        df_sc_pt['Public_Patient_ID'] = ['ST-' + item.split('-')[1] for item in df_sc_pt.index]\n",
    "        df_sc_pt['Shared/Clonal Freq. per Pt.'] = df_sc_pt.loc[:,df_sc_pt.dtypes=='float64'].sum(axis=1)\n",
    "        df_sc_pt['Shared/Clonal No. per Pt.'] = (df_sc_pt.loc[:,df_sc_pt.dtypes=='float64'] > 0).sum(axis=1) - 1\n",
    "        s_clonal_site = s_file.split('Clonal_Site_')[1].split('_Productive_Freq')[0].replace('_',' ')\n",
    "        #add cohorts\n",
    "        for s_sheet in ['Tumor_Type','Blood_Type']:\n",
    "            d_cohort = dict(zip(df_patient.loc[df_patient.loc[:,s_sheet].notna(),'Public_Patient_ID'],df_patient.loc[df_patient.loc[:,s_sheet].notna(),'Cohort']))\n",
    "            print(len(d_cohort))\n",
    "            df_sc_pt[s_sheet.replace('_Type','_Cohort')] = df_sc_pt.Public_Patient_ID.map(d_cohort)\n",
    "        for s_porg in ['pORG_All_quartiles', 'pORG_Met_quartiles','pORG_Primary_quartiles',]:\n",
    "            s_primary_met =  s_porg.split('pORG_')[1].split('_quartiles')[0]\n",
    "            d_score = dict(zip(df_patient.Public_Patient_ID,df_patient.loc[:,s_porg]))\n",
    "            df_sc_pt[s_porg] = df_sc_pt.Public_Patient_ID.map(d_score)\n",
    "            for s_cohort in ['Tumor_Cohort']: #,'Blood_Cohort'\n",
    "                if s_cohort == 'Tumor_Cohort':\n",
    "                    b_site = ~df_sc_pt.index.str.contains('-B')\n",
    "                    if s_porg == 'pORG_Primary_quartiles':\n",
    "                        b_site = df_sc_pt.index.str.contains('-T')\n",
    "                    elif s_porg == 'pORG_Met_quartiles':\n",
    "                        b_site = df_sc_pt.index.str.contains('-M')\n",
    "                elif s_cohort =='Blood_Cohort':\n",
    "                    b_site = df_sc_pt.index.str.contains('-B')\n",
    "                #df = df_sc_pt[(df_sc_pt.loc[:,s_cohort].notna()) & (b_site)].copy()\n",
    "                df = df_sc_pt[(b_site)].copy()\n",
    "                df.loc[:,'Cohort'] = df.loc[:,s_cohort].replace({'none':np.nan})\n",
    "                df['Cohort'] = df['Cohort'].replace({'nan':pd.NA})\n",
    "                df_clones = df.loc[:,[not (any(not c.isupper() for c in item)) for item in df.columns]].copy()\n",
    "                ################################################\n",
    "                #per patient\n",
    "                #'''\n",
    "                for s_col in [s_porg,'Cohort',]:\n",
    "                    if s_col == 'Cohort':\n",
    "                        sns.set_palette(pal_liv_r)\n",
    "                    else:\n",
    "                        sns.set_palette(pal_porg_r)\n",
    "                    for y in ['Shared/Clonal No. per Pt.','Shared/Clonal Freq. per Pt.']:\n",
    "                        ls_groups = sorted(df.loc[:,s_col].dropna().unique())\n",
    "                        print(sorted(df.loc[:,s_col].dropna().value_counts()))\n",
    "                        plotting = {\"data\": df.loc[:,[s_col,y]].dropna(),\"x\":s_col,\"y\":y,\"order\":ls_groups}\n",
    "                        fig, ax, test_results = util.annotated_stripplot(plotting,ls_groups,b_correct=False)\n",
    "                        ax.set_title(f'From: {s_primary_met} {s_cohort.replace(\"_Cohort\",\"s\")}')\n",
    "                        ax.set_xlabel(f\"{s_col.replace('_0.2_',' ').replace('_',' ')}\")\n",
    "                        ax.set_ylabel(f\"{y.replace('/',' ')}\")\n",
    "                        ax.text(x=-0.1, y=-0.1, s='In:',transform=ax.transAxes)\n",
    "                        plt.tight_layout()\n",
    "                        fig.savefig(f\"figures/Shared_clonal_from_{s_cohort.replace('/','_')}_in_{s_col}_{y.replace('/','_')}_{s_primary_met}.pdf\",dpi=300)\n",
    "                        # if y == 'Shared/Clonal Freq. per Pt.':\n",
    "                        #         d_fig_6.update({f\"Figure6_G__from{s_cohort.replace('/','_')}_in_{y}_{s_col.replace('/','_')}_{s_porg.split('_')[1]}\":df.loc[:,[s_col,y]].dropna()})\n",
    "                         \n",
    "                        # if y == 'Shared/Clonal No. per Pt.':\n",
    "                        #         d_fig_6.update({f\"Figure6_F__from{s_cohort.replace('/','_')}_in_{y}_{s_col.replace('/','_')}_{s_porg.split('_')[1]}\":df.loc[:,[s_col,y]].dropna()})\n",
    "    \n",
    "                            #break\n",
    "                    #break\n",
    "                #break blood / tumor\n",
    "            break\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ls_col = ['Public_Patient_ID','Shared/Clonal No. per Pt.','Shared/Clonal Freq. per Pt.',\n",
    "#          'Tumor_Cohort','pORG_All_quartiles']\n",
    "# df.loc[:,ls_col].to_csv(f'Source_Extended_Data_Fig6_F_G_from_All_tumor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(d_fig_6.keys())\n",
    "# #util.open_write_excel(d_fig_6,filename='Source_Data_Figure6.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kras specific samples <a name=\"kras\"></a> \n",
    "\n",
    "\n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_kras = pd.read_excel('TCR/science.abl5447_table_s7.xlsx',sheet_name=None)\n",
    "df_kras=pd.DataFrame()\n",
    "for key, item in d_kras.items():\n",
    "    print(key)\n",
    "    item.rename({'Mutated gene or tumor reactivity':'Antigen','Antigen reactivity':'Antigen'},axis=1,inplace=True)\n",
    "    item['Sheet'] = key\n",
    "    df_kras = pd.concat([df_kras,item.loc[:,['CDR3B','Antigen','Sheet']]])\n",
    "    #break\n",
    "se_kras = df_kras[df_kras.Antigen=='KRAS'].CDR3B\n",
    "# are any shared clonal Kras specific? no\n",
    "try:\n",
    "   df_sc_pt.columns.isin(se_kras).any()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all TCRBs\n",
    "len(set(df_kras.CDR3B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kras TCRBs\n",
    "len(set(se_kras))\n",
    "#set(se_kras)\n",
    "#df_sumt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sc_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#productive freq per sample\n",
    "# print(len(set(se_kras)))\n",
    "#b_kras_non = False#True#False#True# False #include samples without kras?\n",
    "for b_kras_non in [True,False]:\n",
    "    df_tcr_kras = df_tcr_all[df_tcr_all.amino_acid.isin(se_kras)].copy()\n",
    "    print(f'no unique KRAS seqs: {df_tcr_kras.amino_acid.nunique()}')\n",
    "    print(df_tcr_kras.amino_acid.unique())\n",
    "    df_sum = pd.DataFrame(df_tcr_kras.groupby('sample_name').productive_frequency.sum())\n",
    "    df_count = pd.DataFrame(df_tcr_kras.groupby('sample_name').amino_acid.nunique())\n",
    "    if b_kras_non:\n",
    "        df_sum = df_sc_pt.merge(df_sum.rename({'productive_frequency':'KRAS_frequency'},axis=1),\n",
    "                   left_index=True,right_index=True,how='left')\n",
    "        df_sum['KRAS_frequency'] = df_sum.KRAS_frequency.fillna(0)\n",
    "        df_count = df_sc_pt.merge(df_count.rename({'amino_acid':'KRAS_count'},axis=1),\n",
    "                   left_index=True,right_index=True,how='left')\n",
    "        df_count['KRAS_count'] = df_count.KRAS_count.fillna(0)\n",
    "    #sum tumor ONLY\n",
    "    df_sumt=df_sum[~df_sum.index.str.contains('-B')].copy()\n",
    "    df_countt = df_count[~df_count.index.str.contains('-B')].copy()\n",
    "    df_sumt['Patient']=['ST-' + item.split('-')[1] for item in df_sumt.index]\n",
    "    df_countt['Patient']=['ST-' + item.split('-')[1] for item in df_countt.index]\n",
    "    \n",
    "    #any duplicated? no\n",
    "    print(df_sumt.Patient.duplicated().any())\n",
    "    print(df_countt.Patient.duplicated().any())\n",
    "    #d_cohort = \n",
    "    d_cohort = dict(zip(df_patient.loc[:,'Public_Patient_ID'],df_patient.loc[:,'Cohort']))\n",
    "    d_cohort2 = dict(zip(df_patient.loc[:,'Public_Patient_ID'],df_patient.loc[:,'Recurrence_Sites_4']))\n",
    "    df_sc_pt['Public_Patient_ID'] = ['ST-' + item.split('-')[1] for item in df_sc_pt.index]\n",
    "    df_tcr_kras['Public_Patient_ID'] = ['ST-' + item.split('-')[1] for item in df_tcr_kras.sample_name]\n",
    "    s_porg = 'pORG_All_quartiles'\n",
    "    df_tcr_kras['Cohort'] = df_tcr_kras.Public_Patient_ID.map(d_cohort)\n",
    "    df_tcr_kras['Cohort2'] = df_tcr_kras.Public_Patient_ID.map(d_cohort2)\n",
    "    #df_tcr_kras['Blood_Cohort'] =df_tcr_kras.Public_Patient_ID.map(dict(zip(df_sc_pt.Public_Patient_ID,df_sc_pt.Blood_Cohort)))\n",
    "    df_tcr_kras[s_porg] = df_tcr_kras.Public_Patient_ID.map(d_score)\n",
    "    importlib.reload(util)\n",
    "    for  b_count in [False,True,]:# True, #use counts (false = productive freq)\n",
    "        df_out = pd.DataFrame(index=sorted(set(se_kras)))\n",
    "        #add cohort\n",
    "        df_sumt['Cohort'] = pd.NA\n",
    "        df_sumt['Cohort'] = df_sumt.Patient.map(d_cohort)\n",
    "        df_countt['Cohort'] = pd.NA\n",
    "        df_countt['Cohort'] = df_countt.Patient.map(d_cohort)\n",
    "        \n",
    "        df_sumt['Cohort2'] = pd.NA\n",
    "        df_sumt['Cohort2'] = df_sumt.Patient.map(d_cohort2)\n",
    "        \n",
    "        #df_sumt['Blood_Cohort'] =df_sumt.Patient.map(dict(zip(df_sc_pt.Public_Patient_ID,df_sc_pt.Blood_Cohort)))\n",
    "        #df_countt['Blood_Cohort'] =df_countt.Patient.map(dict(zip(df_sc_pt.Public_Patient_ID,df_sc_pt.Blood_Cohort)))\n",
    "        \n",
    "        #add pORG\n",
    "        df_sumt[s_porg] = pd.NA\n",
    "        df_sumt[s_porg] = df_sumt.Patient.map(d_score).replace({'none':pd.NA,np.nan:pd.NA})\n",
    "        df_countt[s_porg] = pd.NA\n",
    "        df_countt[s_porg] = df_countt.Patient.map(d_score).replace({'none':pd.NA,np.nan:pd.NA})\n",
    "        df_sumt['Cohort'] = df_sumt.Cohort.replace({'none':pd.NA,'nan':pd.NA})\n",
    "        #df_sumt.Blood_Cohort = df_sumt.Blood_Cohort.replace({'none':pd.NA})\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "            for s_col in ['Cohort',s_porg]: #'Cohort2','Blood_Cohort',\n",
    "                if s_col == 'Cohort':\n",
    "                    sns.set_palette(pal_liv_r)\n",
    "                elif s_col == 'Cohort2':\n",
    "                    sns.set_palette('tab10')\n",
    "                else:\n",
    "                    sns.set_palette(pal_porg_r)\n",
    "                #for found in data sheet\n",
    "                print(df_tcr_kras[(df_tcr_kras.loc[:,s_col].notna()) & (~df_tcr_kras.sample_name.str.contains('-B'))].replace({'nan':pd.NA}).groupby(s_col).amino_acid.nunique())\n",
    "                df = df_tcr_kras[(df_tcr_kras.loc[:,s_col].notna()) & (~df_tcr_kras.sample_name.str.contains('-B'))].replace({'nan':pd.NA}).groupby(s_col).amino_acid.unique()\n",
    "                for item in df.items():\n",
    "                    df_out[f'{item[0]}_{s_col}'] = pd.NA\n",
    "                    df_out.loc[item[1],f'{item[0]}_{s_col}'] = 'Yes'\n",
    "                    df_out[f'{item[0]}_{s_col}'].fillna('No',inplace=True)\n",
    "                #plot\n",
    "                ls_groups = sorted(df_sumt.loc[:,s_col].dropna().unique())\n",
    "                if b_count:\n",
    "                    y = 'amino_acid'#'templates'#\n",
    "                    if b_kras_non:\n",
    "                        y='KRAS_count'\n",
    "                    plotting = {\"data\": df_countt[df_countt.loc[:,s_col].notna()],\"x\":s_col,\"y\":y,\"order\":ls_groups}\n",
    "                    ylabel ='No. KRAS-Specific CDR3 per Pt.'\n",
    "                else:\n",
    "                    y = 'productive_frequency'#'templates'#\n",
    "                    if b_kras_non:\n",
    "                        y='KRAS_frequency'\n",
    "                    plotting = {\"data\": df_sumt[df_sumt.loc[:,s_col].notna()],\"x\":s_col,\"y\":y,\"order\":ls_groups}\n",
    "                    print(sorted(df_sumt.loc[:,s_col].dropna().value_counts()))\n",
    "                    ylabel='CDR3 Frequency'\n",
    "                fig, ax, test_results = util.annotated_stripplot(plotting,ls_groups,'')\n",
    "                for res in test_results:\n",
    "                    pvalue = res.data.pvalue\n",
    "                    print(pvalue)\n",
    "                if not s_col == 'Cohort2':\n",
    "                    if  b_count:\n",
    "                        ax.set_title(f\"No. KRAS CDR3 Sequences\\nvs. {s_col.replace('_All_',' ')}\",fontsize='small')#\\np={pvalue:.2}\n",
    "                    else:\n",
    "                        ax.set_title(f\"KRAS CDR3 Frequency\\nvs. {s_col.replace('_All_',' ')}\",fontsize='small')#\\np={pvalue:.2}\n",
    "                else:\n",
    "                    ax.set_title(f\"KRAS Specific Frequency in All Sites\")\n",
    "                ax.set_xlabel(f\"{s_col.replace('_0.2_',' ').replace('_',' ')}\")\n",
    "                ax.set_ylabel(ylabel)\n",
    "                plt.tight_layout()\n",
    "                fig.savefig(f'figures/stripplot_KRAS_freq_{s_col}_count_{b_count}_non_{b_kras_non}.pdf')\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sumt.columns.isin(['CASRQGNTGELFF' 'CASSLGQTNYGYTF' 'CASSQGNTGELFF' 'CASSPGTENSPLHF'\n",
    " 'CASRIGNTGELFF' 'CASSDPGTEAFF' 'CASSLGRASNQPQHF' 'CASRNLGDTQYF'\n",
    " 'CASKVYGYTF' 'CASGDTGGYEQYF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sumt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting['data']\n",
    "#df_countt\n",
    "#df_sumt.to_csv(f'Source_Extended_Data_Figure9_L.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_countt.to_csv('Source_Data_Figure7_I.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sumt.to_csv('Source_Data_Figure7_J.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#survival - tumor\n",
    "df_patient['KRAS Specific TCRs Tumor'] = pd.NA\n",
    "df_patient.loc[df_patient.Clonality_Tumor.notna(),'KRAS Specific TCRs Tumor']= 'False'\n",
    "df_patient.loc[df_patient.Public_Patient_ID.isin(df_sumt.Patient),'KRAS Specific TCRs Tumor']= 'True'\n",
    "df_patient['KRAS Specific TCRs Tumor'].value_counts()\n",
    "s_time = 'Days from Diagnosis to FU'\n",
    "s_censor = 'Survival'\n",
    "df_km = df_patient.loc[df_patient.Alive_30_days_post_surgery,['Public_Patient_ID','KRAS Specific TCRs Tumor',s_time,s_censor]].dropna()\n",
    "fig, ax, __ = util.km_plot(df_km,'KRAS Specific TCRs Tumor',s_time,s_censor)\n",
    "fig.savefig(f'figures/KM_KRAS_Tumor_all.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls_col = ['Public_Patient_ID','Percent Tumor Distinct Clones','KRAS Specific TCRs Blood','KRAS Specific TCRs Tumor',\n",
    "#          'Survival','Days from Diagnosis to FU']\n",
    "# df_patient.loc[:,ls_col].to_csv('Source_Data_Figure7_H_K.csv')\n",
    "# #df_patient.columns[df_patient.columns.str.contains('Days')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#survival - liver or lung cohort\n",
    "df_patient['KRAS Specific TCRs Tumor + Cohort'] = pd.NA\n",
    "df_patient.loc[(df_patient.Clonality_Tumor.notna()) & (df_patient.Cohort.notna()),'KRAS Specific TCRs Tumor + Cohort']= 'False'\n",
    "df_patient.loc[(df_patient.Public_Patient_ID.isin(df_sumt.Patient)) & (df_patient.Cohort.notna()),'KRAS Specific TCRs Tumor + Cohort']= 'True'\n",
    "df_patient['KRAS Specific TCRs Tumor + Cohort'].value_counts()\n",
    "s_time = 'Days from Diagnosis to FU'\n",
    "s_censor = 'Survival'\n",
    "df_km = df_patient.loc[df_patient.Alive_30_days_post_surgery,['Public_Patient_ID','KRAS Specific TCRs Tumor + Cohort',s_time,s_censor]].dropna()\n",
    "fig,ax,ls_order = util.km_plot(df_km,'KRAS Specific TCRs Tumor + Cohort',s_time,s_censor)\n",
    "ax.set_title('KRAS Specific TCRs Tumor\\n Liver and Lung Cohort Patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sum blood\n",
    "df_sumb=df_sum[df_sum.index.str.contains('-B')].copy()\n",
    "df_sumb['Patient']=['ST-' + item.split('-')[1] for item in df_sumb.index]\n",
    "df_sumb['Cohort'] = df_sumb.Patient.map(d_cohort).replace({'none':pd.NA,'nan':pd.NA})\n",
    "df_sumb[s_porg] = df_sumb.Patient.map(d_score).replace({'none':pd.NA,np.nan:pd.NA})\n",
    "\n",
    "for s_col in ['Cohort',s_porg]: #'Blood_Cohort',\n",
    "    print(df_tcr_kras[(df_tcr_kras.loc[:,s_col].notna()) & (df_tcr_kras.sample_name.str.contains('-B'))].replace({'nan':pd.NA}).groupby(s_col).amino_acid.nunique())\n",
    "    ls_groups = sorted(df_sumb.loc[:,s_col].dropna().unique())\n",
    "    y = 'productive_frequency'#'templates'#\n",
    "    plotting = {\"data\": df_sumb[df_sumb.loc[:,s_col].notna()],\"x\":s_col,\"y\":y,\"order\":ls_groups}\n",
    "    print(sorted(df_sumb.loc[:,s_col].dropna().value_counts()))\n",
    "    fig, ax, test_results = util.annotated_stripplot(plotting,ls_groups,'')\n",
    "    for res in test_results:\n",
    "        pvalue = res.data.pvalue\n",
    "    ax.set_title(f\"KRAS in {s_col.replace('_0.2_All_',' ')} Blood\\np={pvalue:.2}\")\n",
    "    # ax.set_ylabel('CD3R Frequency')\n",
    "    ax.set_xlabel(f\"{s_col.replace('_0.2_',' ').replace('_',' ')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#survival blood\n",
    "df_patient['KRAS Specific TCRs Blood'] = pd.NA\n",
    "df_patient.loc[df_patient.Clonality_Blood.notna(),'KRAS Specific TCRs Blood']= 'False'\n",
    "df_patient.loc[df_patient.Public_Patient_ID.isin(df_sumb.Patient),'KRAS Specific TCRs Blood']= 'True'\n",
    "df_patient['KRAS Specific TCRs Blood'].value_counts()\n",
    "s_time = 'Days from Diagnosis to FU'\n",
    "s_censor = 'Survival'\n",
    "df_km = df_patient.loc[df_patient.Alive_30_days_post_surgery,['Public_Patient_ID','KRAS Specific TCRs Blood',s_time,s_censor]].dropna()\n",
    "fig, ax, __ = util.km_plot(df_km,'KRAS Specific TCRs Blood',s_time,s_censor)\n",
    "fig.savefig(f'figures/KM_KRAS_Blood_all.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#survival - both\n",
    "df_patient['KRAS Specific TCRs All'] = pd.NA\n",
    "df_patient.loc[(df_patient.Clonality_Blood.notna()) | (df_patient.Clonality_Tumor.notna()),'KRAS Specific TCRs All']= 'False'\n",
    "df_patient.loc[(df_patient.Public_Patient_ID.isin(df_sumb.Patient)) | (df_patient.Public_Patient_ID.isin(df_sumt.Patient)),'KRAS Specific TCRs All']= 'True'\n",
    "df_patient['KRAS Specific TCRs All'].value_counts()\n",
    "s_time = 'Days from Diagnosis to FU'\n",
    "s_censor = 'Survival'\n",
    "df_km = df_patient.loc[df_patient.Alive_30_days_post_surgery,['Public_Patient_ID','KRAS Specific TCRs All',s_time,s_censor]].dropna()\n",
    "util.km_plot(df_km,'KRAS Specific TCRs All',s_time,s_censor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls_y = ['Productive_Rearrangements',\n",
    "        'Templates_per_ng',\n",
    "        'Shannon_Entropy_Tumor',\n",
    "        'Clonality_Tumor',\n",
    "        \"Simpson's Evenness tumor\",\n",
    "        'Percent Tumor Distinct Clones'\n",
    "       ]\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    for y in ls_y:\n",
    "        s_col ='KRAS Specific TCRs Tumor' #'Blood_Cohort',\n",
    "        ls_groups = sorted(df_patient.loc[:,s_col].dropna().unique())\n",
    "        plotting = {\"data\": df_patient[df_patient.loc[:,s_col].notna()],\n",
    "                    \"x\":s_col,\"y\":y,\"order\":ls_groups}\n",
    "        print(sorted(df_patient.loc[:,s_col].dropna().value_counts()))\n",
    "        fig, ax, test_results = util.annotated_stripplot(plotting,ls_groups)\n",
    "        for res in test_results:\n",
    "            pvalue = res.data.pvalue\n",
    "        #ax.set_title(f\"KRAS vs. {y.replace('_',' ')}\\np={pvalue:.2}\")\n",
    "        ax.legend().remove()\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(f'figures/KRAS_in_tumors_vs_{y}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # are tumor distinct clones KRAS specific?\n",
    "# ls_col = ['Public_Patient_ID','KRAS Specific TCRs Tumor','Productive_Rearrangements','Shannon_Entropy_Tumor']\n",
    "# df_patient.loc[:,ls_col].dropna().to_csv(f'Source_Extended_Data_Figure9_M.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## number of sequences <a name=\"tcrnum\"></a> \n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#load data\n",
    "df_tcr_pt = pd.read_csv('Supplemental_Data/Supplemental_Dataset_8.csv',\n",
    "                          index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tcr_all\n",
    "df_numbers = df_tcr_all.groupby('sample_name').templates.sum().reset_index()\n",
    "d_replace = {'B':'Blood', 'M':'Met', 'Ma':'Met', 'Mb':'Met', 'T':'Primary'}\n",
    "df_numbers['Site'] = [d_replace[item.split('-')[-1]] for item in df_numbers.sample_name]\n",
    "df_numbers['Public_Patient_ID'] = ['ST-' + item.split('-')[1] for item in df_numbers.sample_name]\n",
    "df_numbers['Cohort'] = df_numbers.Public_Patient_ID.map(dict(zip(df_tcr_pt.Public_Patient_ID,df_tcr_pt.Cohort)))\n",
    "df_numbers['Cohort_Site'] = df_numbers.Cohort + '_' + df_numbers.Site\n",
    "for s_porg in ['pORG_All_quartiles','pORG_Primary_quartiles','pORG_Met_quartiles']:\n",
    "    df_numbers[s_porg] = df_numbers.Public_Patient_ID.map(dict(zip(df_tcr_pt.Public_Patient_ID,df_tcr_pt.loc[:,s_porg])))\n",
    "    df_numbers[f'{s_porg}_Site'] = df_numbers.loc[:,s_porg] + '_' + df_numbers.Site\n",
    "ls_blood = [\"Simpson's Evenness blood\",\n",
    " 'Shannon_Entropy_Blood', 'Simpsons_Diversity_Blood',\n",
    " #'Fraction Tumor Distinct TCRs',\n",
    "            'Percent Tumor Distinct Clones']\n",
    "ls_tum = ['Templates_per_ng', 'Productive_Rearrangements', 'Simpsons_Diversity_Tumor', 'Clonality_Tumor',\n",
    " 'Shannon_Entropy_Tumor', 'Clonality_Blood',\"Simpson's Evenness tumor\",]\n",
    "for s_blood in ls_blood:\n",
    "    df_numbers[s_blood] = df_numbers.Public_Patient_ID.map(dict(zip(df_tcr_pt.Public_Patient_ID,df_tcr_pt.loc[:,s_blood])))\n",
    "    df_numbers.loc[df_numbers.Site!='Blood',s_blood]=np.nan\n",
    "    \n",
    "for s_blood in ls_tum:\n",
    "    df_numbers[s_blood] = df_numbers.Public_Patient_ID.map(dict(zip(df_tcr_pt.Public_Patient_ID,df_tcr_pt.loc[:,s_blood])))\n",
    "    df_numbers.loc[df_numbers.Site=='Blood',s_blood]=np.nan\n",
    "    \n",
    "#add Type_Site\n",
    "d_blood_type = dict(zip(df_tcr_pt.Public_Patient_ID + '-B',df_tcr_pt.Blood_Type + '_Bld'))\n",
    "df_numbers['Blood_Type'] = df_numbers.sample_name.map(d_blood_type)#.value_counts()\n",
    "d_tumor_type = dict(zip(df_tcr_pt.Public_Patient_ID,df_tcr_pt.Tumor_Type + '_Tum'))\n",
    "df_numbers['Tumor_Type_temp'] =df_numbers.Public_Patient_ID.map(d_tumor_type)\n",
    "df_numbers['Type_Site'] = df_numbers['Blood_Type'].fillna(df_numbers['Tumor_Type_temp'])#\n",
    "df_numbers['Cohort_Type_Site'] = df_numbers.Cohort + '_' + df_numbers.Type_Site\n",
    "df_numbers['Type_Site'].value_counts()\n",
    "for s_str in ['Primary','Met']:\n",
    "    df_numbers[f'Cohort_{s_str}_Site'] = df_numbers['Cohort_Type_Site']\n",
    "    df_numbers.loc[~(df_numbers.Cohort_Type_Site.str.contains(s_str).fillna(False)),f'Cohort_{s_str}_Site'] = np.nan\n",
    "df_numbers['Cohort_Primary_Site'] = [item.replace('Primary','Pri') for item in df_numbers['Cohort_Primary_Site'].fillna('__')]\n",
    "df_numbers['Cohort_Primary_Site'] = df_numbers.Cohort_Primary_Site.replace('__',np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacer(str):\n",
    "    linebreak = '\\n'\n",
    "    str = str.replace(\"Liver_\",f\"Liver Cohort{linebreak}\").replace(\"Lung_\",\n",
    "        f\"Lung Cohort{linebreak}\").replace(\"low_\",f\"Low pORG{linebreak}\").replace(\"high_\",\n",
    "        f\"High pORG{linebreak}\").replace(\"_\",\" \").replace(\"Tum\",\"Tumor\").replace(\"Bld\",\"Blood\")\n",
    "    return(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot numbers\n",
    "\n",
    "sns.palplot(mpl.cm.tab10.colors)\n",
    "sns.palplot(mpl.cm.tab10_r.colors[-4::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot numbersOld boxplots\n",
    "importlib.reload(util)\n",
    "\n",
    "import itertools\n",
    "from statannotations.Annotator import Annotator\n",
    "y='templates'#'amino_acid'\n",
    "ls_x = ['Site','pORG_Met_quartiles_Site',\n",
    "        'Cohort_Met_Site',\n",
    "        'Cohort_Primary_Site',\n",
    "    'pORG_Primary_quartiles_Site',\n",
    "        ]\n",
    "df_out = pd.DataFrame()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    for x in ls_x:\n",
    "        if x.find('pORG') > -1:\n",
    "            sns.set_palette(mpl.cm.tab10.colors[2:4]+mpl.cm.tab10.colors[0:2])\n",
    "        else:\n",
    "            sns.set_palette(mpl.cm.tab10_r.colors[-4::])\n",
    "        ls_blood = sorted(df_numbers.loc[df_numbers.loc[:,x].str.contains('Bl').fillna(False),x].unique())\n",
    "        ls_tumor = sorted(df_numbers.loc[~(df_numbers.loc[:,x].str.contains('Bl').fillna(True)),x].unique())\n",
    "        order = ls_blood + ls_tumor#sorted(df_numbers.loc[:,x].dropna().unique())\n",
    "        #order = order[::-1] #reverse for liver lung\n",
    "        print(len(order))\n",
    "        if len(order) == 3:\n",
    "            pairs= [item for item in itertools.combinations(order, 2)]\n",
    "            ls_groups = order\n",
    "        else:\n",
    "            pairs = [ls_blood,ls_tumor]#\n",
    "        plotting = {'data':df_numbers,'x':x,'y':y}\n",
    "        fig,ax, test_results, plotorder,pairs2 = util.annotated_stripplot_pairs(plotting,pairs,order)\n",
    "        if len(order) == 4:\n",
    "            ls_groups = []\n",
    "            for res in test_results:\n",
    "                ls_groups.append(res.data.group1)\n",
    "                ls_groups.append(res.data.group2)\n",
    "        ax.set_title(f'{x.replace(\"Site\",\"\").replace(\"_\",\" \").replace(\"Cohort\",\"Cohort:\")}',fontsize='x-large')\n",
    "        ax = util.labels_with_n(plotting,ls_groups,ax)\n",
    "        label = ax.get_xticklabels()\n",
    "        labels = [replacer(item.get_text()) for item in label]\n",
    "        ax.set_xticklabels(labels,fontsize='large')\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(f'Total {ax.get_ylabel()}')\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(f'figures/TCR_{y}_per_sample_vs_{x}.pdf')\n",
    "        df_out = pd.concat([df_out,df_numbers])\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## ImmArch file format\n",
    "# # - \"Clones\" - number of barcodes (events, UMIs) or reads;\n",
    "# # - \"Proportion\" - proportion of barcodes (events, UMIs) or reads;\n",
    "# # - \"CDR3.nt\" - CDR3 nucleotide sequence;\n",
    "# # - \"CDR3.aa\" - CDR3 amino acid sequence;\n",
    "# # - \"V.name\" - names of aligned Variable gene segments;\n",
    "# # - \"D.name\" - names of aligned Diversity gene segments or NA;\n",
    "# # - \"J.name\" - names of aligned Joining gene segments;\n",
    "# # - \"V.end\" - last positions of aligned V gene segments (1-based);\n",
    "# # - \"D.start\" - positions of D'5 end of aligned D gene segments (1-based);\n",
    "# # - \"D.end\" - positions of D'3 end of aligned D gene segments (1-based);\n",
    "# # - \"J.start\" - first positions of aligned J gene segments (1-based);\n",
    "# # - \"VJ.ins\" - number of inserted nucleotides (N-nucleotides) at V-J junction (-1 for receptors with VDJ recombination);\n",
    "# # - \"VD.ins\" - number of inserted nucleotides (N-nucleotides) at V-D junction (-1 for receptors with VJ recombination);\n",
    "# # - \"DJ.ins\" - number of inserted nucleotides (N-nucleotides) at D-J junction (-1 for receptors with VJ recombination);\n",
    "# # - \"Sequence\" - full nucleotide sequence.\n",
    "# d_rename = {'templates':'Clones','productive_frequency':'Proportion',\n",
    "#              'rearrangement':\"CDR3.nt\",'amino_acid':\"CDR3.aa\",\n",
    "#            'v_resolved':\"V.name\", 'd_resolved':\"D.name\", 'j_resolved':\"J.name\"}\n",
    "# for idx, s_sample in enumerate(df_tcr_all.sample_name.unique()):\n",
    "#     print(505 - idx)\n",
    "#     df_sample = df_tcr_all[df_tcr_all.sample_name==s_sample].copy()\n",
    "#     df_sample = df_sample.rename(d_rename,axis=1).replace('unknown',np.nan)\n",
    "#     df_out = df_sample.loc[:,[item for key, i`tem in d_rename.items()]]\n",
    "#     df_out.to_csv(f'TCR/raw_data/TCR_raw_data_{s_sample}.csv')\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_numbers.to_csv(f'Source_Extended_Data_Figure7_A-C.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #make a metadata\n",
    "# #The metadata file “metadata.txt” has to be a table with first column named “Sample” \n",
    "# #and any number of additional columns with any names. The first column should contain \n",
    "# #the base names of files without extensions in your folder.\n",
    "# df_meta = pd.DataFrame(index=os.listdir(f'TCR/raw_data/'))\n",
    "\n",
    "# df_meta['sample_name'] = [item.split('_')[-1].split('.csv')[0] for item in df_meta.index]\n",
    "# df_metaindex = [item.split('.csv')[0] for item in df_meta.index]\n",
    "# # add metadata \n",
    "# ls_col = ['sample_name','templates', 'Site', 'Public_Patient_ID', 'Cohort',\n",
    "#        'Cohort_Site', 'pORG_0.2_All_quartiles', 'pORG_0.2_All_quartiles_Site',\n",
    "#        'pORG_0.2_Primary_quartiles', 'pORG_0.2_Primary_quartiles_Site',\n",
    "#        'pORG_0.2_Met_quartiles', 'pORG_0.2_Met_quartiles_Site', 'Blood_Type', \n",
    "#        'Type_Site', 'Cohort_Type_Site', 'Cohort_Primary_Site',\n",
    "#        'Cohort_Met_Site']\n",
    "# df_meta = df_meta.merge(df_number.loc[:,ls_col],on='sample_name').set_index('sample_name')\n",
    "# df_meta.index.name = 'Sample'\n",
    "# df_meta.to_csv('metadata.txt',sep ='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for s in ['pORG_0.2_Primary_quartiles_Site','pORG_0.2_Met_quartiles_Site',\n",
    "#          'Cohort_Primary_Site','Cohort_Met_Site']:\n",
    "#     print(df_meta.loc[:,s].unique())\n",
    "# df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = 'templates'\n",
    "# for s_blood in ls_blood + ls_tum:\n",
    "#     fig,ax=plt.subplots(dpi=200)\n",
    "#     sns.regplot(data=df_number,x=s_blood,y=y,ax=ax)\n",
    "#     y_array = df_number.loc[:,[s_blood,y]].dropna().loc[:,s_blood]\n",
    "#     x_array = df_number.loc[y_array.index,y]\n",
    "#     statistic, pvalue = stats.spearmanr(x_array, y_array)\n",
    "#     ax.set_title(f'{s_blood} r={statistic:.3} p={pvalue:.3}')\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique productive rearrangements\n",
    "df_number = df_tcr_all.groupby('sample_name').amino_acid.nunique().reset_index()\n",
    "d_replace = {'B':'Blood', 'M':'Met', 'Ma':'Met', 'Mb':'Met', 'T':'Primary'}\n",
    "df_number['Site'] = [d_replace[item.split('-')[-1]] for item in df_number.sample_name]\n",
    "df_number.loc[df_number.sample_name=='ST-00015839-T','Site'] = 'Met'\n",
    "df_number['Public_Patient_ID'] = ['ST-' + item.split('-')[1] for item in df_number.sample_name]\n",
    "df_number['Cohort'] = df_number.Public_Patient_ID.map(dict(zip(df_tcr_pt.Public_Patient_ID,df_tcr_pt.Cohort)))\n",
    "df_number['Cohort_Site'] = df_number.Cohort + '_' + df_number.Site\n",
    "for s_porg in ['pORG_All_quartiles','pORG_Primary_quartiles','pORG_Met_quartiles']:\n",
    "    df_number[s_porg] = df_number.Public_Patient_ID.map(dict(zip(df_tcr_pt.Public_Patient_ID,df_tcr_pt.loc[:,s_porg])))\n",
    "    df_number[f'{s_porg}_Site'] = df_number.loc[:,s_porg] + '_' + df_number.Site\n",
    "ls_blood = [\"Simpson's Evenness blood\",\n",
    " 'Shannon_Entropy_Blood', 'Simpsons_Diversity_Blood',\n",
    " 'Percent Tumor Distinct Clones']\n",
    "ls_tum = ['Templates_per_ng', 'Productive_Rearrangements', 'Simpsons_Diversity_Tumor', 'Clonality_Tumor',\n",
    " 'Shannon_Entropy_Tumor', 'Clonality_Blood',\"Simpson's Evenness tumor\",]\n",
    "for s_blood in ls_blood:\n",
    "    df_number[s_blood] = df_number.Public_Patient_ID.map(dict(zip(df_tcr_pt.Public_Patient_ID,df_tcr_pt.loc[:,s_blood])))\n",
    "    df_number.loc[df_number.Site!='Blood',s_blood]=np.nan\n",
    "    \n",
    "for s_blood in ls_tum:\n",
    "    df_number[s_blood] = df_number.Public_Patient_ID.map(dict(zip(df_tcr_pt.Public_Patient_ID,df_tcr_pt.loc[:,s_blood])))\n",
    "    df_number.loc[df_number.Site=='Blood',s_blood]=np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sanity check\n",
    "y = 'amino_acid'\n",
    "for s_blood in ls_blood + ls_tum:\n",
    "    s_blood = 'Productive_Rearrangements'\n",
    "    fig,ax=plt.subplots(dpi=200)\n",
    "    sns.regplot(data=df_number,x=s_blood,y=y,ax=ax)\n",
    "    y_array = df_number.loc[:,[s_blood,y]].dropna().loc[:,s_blood]\n",
    "    x_array = df_number.loc[y_array.index,y]\n",
    "    statistic, pvalue = stats.spearmanr(x_array, y_array)\n",
    "    ax.set_title(f'{s_blood} r={statistic:.3} p={pvalue:.3}')\n",
    "    break\n",
    "# df_number.iloc[:,0:4].to_csv('results_Productive_rearrangements.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pie charts <a name=\"tcrpie\"></a> \n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie charts\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n",
    "# sizes = [15, 30, 45, 10]\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.pie(sizes, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tcr_pt = pd.read_csv('annotation/20231108_Patient_Metadata_TCR_Metrics.csv',index_col=0)\n",
    "#load data\n",
    "df_tcr_pt = pd.read_csv('Supplemental_Data/Supplemental_Dataset_8.csv',\n",
    "                          index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate blood and tumor shared\n",
    "d_replace = {'B':'Blood', 'M':'Met', 'Ma':'Met', 'Mb':'Met', 'T':'Primary'}\n",
    "df_tcr_all['Site'] = [d_replace[item.split('-')[-1]] for item in df_tcr_all.sample_name]\n",
    "df_bld = df_tcr_all[df_tcr_all.Site == 'Blood']\n",
    "df_tum = df_tcr_all[df_tcr_all.Site != 'Blood']\n",
    "es_shared = set(df_bld.amino_acid).intersection(set(df_tum.amino_acid))\n",
    "df_tcr_shared = df_tcr_all[df_tcr_all.amino_acid.isin(es_shared)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#34% shared seqs\n",
    "print(len(df_tcr_shared)/len(df_tcr_all))\n",
    "set([item.split('-')[-1] for item in df_tcr_all.sample_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tcr_all.productive_frequency.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se_all = df_tcr_all.loc[:,['sample_name','amino_acid']].groupby('sample_name').nunique()\n",
    "# se_shared = df_tcr_shared.loc[:,['sample_name','amino_acid']].groupby('sample_name').nunique()\n",
    "\n",
    "# se_all_sum = df_tcr_all.loc[:,['sample_name','templates']].groupby('sample_name').sum()\n",
    "# se_shared_sum = df_tcr_shared.loc[:,['sample_name','templates']].groupby('sample_name').sum()\n",
    "\n",
    "# df_proportion_shared = se_shared/se_all\n",
    "# df_proportion_shared.rename({'amino_acid':'proportion_shared_clones'},axis=1,inplace=True)\n",
    "\n",
    "# df_proportion_shared_sum = se_shared_sum/se_all_sum\n",
    "# df_proportion_shared_sum.rename({'templates':'proportion_shared_templates'},axis=1,inplace=True)\n",
    "# df_proportion_shared.merge(df_proportion_shared_sum,left_index=True,right_index=True).to_csv('results_TCR_proportion_shared_clones.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #each sample has a total number of templates of an aa rearrangement\n",
    "# s_grouper = 'amino_acid'#'rearrangement' #\n",
    "# df_number = df_tcr_all.groupby(['sample_name',s_grouper]).templates.sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #df_tcr_all.head()\n",
    "# #s_grouper = 'amino_acid'#'rearrangement' #\n",
    "# df_pri = df_tcr_all[df_tcr_all.Site == 'Primary']\n",
    "# df_met = df_tcr_all[df_tcr_all.Site == 'Met']\n",
    "# df_number_pri = df_pri.groupby([s_grouper]).templates.sum().reset_index()\n",
    "# df_number_pri = df_number_pri.sort_values(by='templates')\n",
    "# df_number_met = df_met.groupby([s_grouper]).templates.sum().reset_index()\n",
    "# df_number_met = df_number_met.sort_values(by='templates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_number['Site'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #for each rearracngement, how many are there with one template, two template, etc\n",
    "# #df_number = df_number_all.groupby(['templates','sample_name']).count().reset_index()\n",
    "# #df_number.rename({'amino_acid':'number of clones','templates':'clone size'},axis=1,inplace=True)\n",
    "# d_replace = {'B':'Blood', 'M':'Met', 'Ma':'Met', 'Mb':'Met', 'T':'Primary'}\n",
    "# df_number['Site'] = [d_replace[item.split('-')[-1]] for item in df_number.sample_name]\n",
    "# #df_number.loc[df_number.sample_name=='ST-00015839-T','Site'] = 'Met'\n",
    "# df_number['Public_Patient_ID'] = ['ST-' + item.split('-')[1] for item in df_number.sample_name]\n",
    "# df_number['Cohort'] = df_number.Public_Patient_ID.map(dict(zip(df_tcr_pt.Public_Patient_ID,df_tcr_pt.Cohort)))\n",
    "# df_number['Cohort_Site'] = df_number.Cohort + '_' + df_number.Site\n",
    "# for s_porg in ['pORG_All_quartiles','pORG_Primary_quartiles','pORG_Met_quartiles']:\n",
    "#     df_number[s_porg] = df_number.Public_Patient_ID.map(dict(zip(df_tcr_pt.Public_Patient_ID,df_tcr_pt.loc[:,s_porg])))\n",
    "#     df_number[f'{s_porg}_Site'] = df_number.loc[:,s_porg] + '_' + df_number.Site\n",
    "    \n",
    "# #add Type_Site\n",
    "# d_blood_type = dict(zip(df_tcr_pt.Public_Patient_ID + '-B',df_tcr_pt.Blood_Type + '_Bld'))\n",
    "# df_number['Blood_Type'] = df_number.sample_name.map(d_blood_type)#.value_counts()\n",
    "# d_tumor_type = dict(zip(df_tcr_pt.Public_Patient_ID,df_tcr_pt.Tumor_Type + '_Tum'))\n",
    "# df_number['Tumor_Type_temp'] =df_number.Public_Patient_ID.map(d_tumor_type)\n",
    "# df_number['Type_Site'] = df_number['Blood_Type'].fillna(df_number['Tumor_Type_temp'])#\n",
    "# df_number['Cohort_Type_Site'] = df_number.Cohort + '_' + df_number.Type_Site\n",
    "# df_number['Type_Site'].value_counts()\n",
    "# for s_str in ['Primary','Met']:\n",
    "#     df_number[f'Cohort_{s_str}_Site'] = df_number['Cohort_Type_Site']\n",
    "#     df_number.loc[~(df_number.Cohort_Type_Site.str.contains(s_str).fillna(False)),f'Cohort_{s_str}_Site'] = pd.NA\n",
    "# df_number['Cohort_Primary_Site'] = [item.replace('Primary','Pri') for item in df_number['Cohort_Primary_Site'].fillna('__')]\n",
    "# df_number['Cohort_Primary_Site'] = df_number.Cohort_Primary_Site.replace('__',np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expanded in tumors\n",
    "df_group = df_tum\n",
    "df_plot = df_group.loc[:,['amino_acid','templates','sample_name']].groupby(['amino_acid','sample_name']).sum().sort_values(by='templates').reset_index()\n",
    "idx = (df_plot.sample_name.nunique())\n",
    "df_plot_large = df_plot[df_plot.loc[:,'templates']>idx].copy()\n",
    "df_plot_large_pri = df_plot_large.loc[df_plot_large.sample_name.str.contains('-T'),['amino_acid','templates']]\n",
    "df_plot_large_met = df_plot_large.loc[df_plot_large.sample_name.str.contains('-M'),['amino_acid','templates']]\n",
    "print(df_plot[df_plot.sample_name.str.contains('-T')].sample_name.nunique())\n",
    "print(df_plot[df_plot.sample_name.str.contains('-M')].sample_name.nunique())\n",
    "df_plot_large_pri = df_plot_large_pri.groupby('amino_acid').sum()\n",
    "df_plot_large_met = df_plot_large_met.groupby('amino_acid').sum()\n",
    "i_small_pri = df_plot[(df_plot.loc[:,'templates']<=idx) & (df_plot.sample_name.str.contains('-T'))].templates.sum()\n",
    "i_small_met = df_plot[(df_plot.loc[:,'templates']<=idx) & (df_plot.sample_name.str.contains('-M'))].templates.sum()\n",
    "df_plot_large_pri.loc[1] = i_small_pri\n",
    "df_plot_large_met.loc[1] = i_small_met\n",
    "#pri\n",
    "sizes = df_plot_large_pri.sort_values(by='templates').templates #df_plot_large_pri.loc[:,'templates']\n",
    "labels = [''] * len(sizes)\n",
    "fig, ax = plt.subplots(dpi=300)\n",
    "_ = ax.pie(sizes, labels=labels,autopct = lambda p : f\"{p:.3}%\" if p >1  else f\"\")\n",
    "fig.savefig(f'figures/pie_primary_tumor.pdf')\n",
    "#mets\n",
    "sizes = df_plot_large_met.sort_values(by='templates').templates #df_plot_large_pri.loc[:,'templates']\n",
    "labels = [''] * len(sizes)\n",
    "fig, ax = plt.subplots(dpi=300)\n",
    "_ = ax.pie(sizes, labels=labels,autopct = lambda p : f\"{p:.3}%\" if p >1  else f\"\")\n",
    "fig.savefig(f'figures/pie_met_tumor.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#expanded in blood\n",
    "# df_plot_large_pri.sort_values(by='templates').to_csv('Source_Data_Figure5_J_pt1.csv')\n",
    "# df_plot_large_met.sort_values(by='templates').to_csv('Source_Data_Figure5_J_pt2.csv')\n",
    "ls_pri = [item + '-B' for item in df_tcr_pt[df_tcr_pt.Blood_Type=='Primary'].Public_Patient_ID]\n",
    "ls_met = [item + '-B' for item in df_tcr_pt[df_tcr_pt.Blood_Type=='Met'].Public_Patient_ID]\n",
    "df_group = df_bld\n",
    "df_plot = df_group.loc[:,['amino_acid','templates','sample_name']].groupby(['amino_acid','sample_name']).sum().sort_values(by='templates').reset_index()\n",
    "idx = (df_plot.sample_name.nunique())\n",
    "df_plot_large = df_plot[df_plot.loc[:,'templates']>idx].copy()\n",
    "df_plot_large_pri = df_plot_large.loc[df_plot_large.sample_name.isin(ls_pri),['amino_acid','templates']]\n",
    "df_plot_large_met = df_plot_large.loc[df_plot_large.sample_name.isin(ls_met),['amino_acid','templates']]\n",
    "df_plot_large_pri = df_plot_large_pri.groupby('amino_acid').sum()\n",
    "df_plot_large_met = df_plot_large_met.groupby('amino_acid').sum()\n",
    "print(df_plot[df_plot.sample_name.isin(ls_pri)].sample_name.nunique())\n",
    "print(df_plot[df_plot.sample_name.isin(ls_met)].sample_name.nunique())\n",
    "i_small_pri = df_plot[(df_plot.loc[:,'templates']<=idx) & (df_plot.sample_name.isin(ls_pri))].templates.sum()\n",
    "i_small_met = df_plot[(df_plot.loc[:,'templates']<=idx) & (df_plot.sample_name.isin(ls_met))].templates.sum()\n",
    "df_plot_large_pri.loc['small'] = i_small_pri\n",
    "df_plot_large_met.loc['small'] = i_small_met\n",
    "#pri\n",
    "'''\n",
    "sizes = df_plot_large_pri.sort_values(by='templates').templates #df_plot_large_pri.loc[:,'templates']\n",
    "labels = [''] * len(sizes)\n",
    "fig, ax = plt.subplots(dpi=300)\n",
    "_ = ax.pie(sizes, labels=labels,autopct = lambda p : f\"{p:.3}%\" if p >1  else f\"\")\n",
    "fig.savefig(f'figures/pie_primary_blood.pdf')\n",
    "#mets\n",
    "sizes = df_plot_large_met.sort_values(by='templates').templates #df_plot_large_pri.loc[:,'templates']\n",
    "labels = [''] * len(sizes)\n",
    "fig, ax = plt.subplots(dpi=300)\n",
    "_ = ax.pie(sizes, labels=labels,autopct = lambda p : f\"{p:.3}%\" if p >1  else f\"\")\n",
    "fig.savefig(f'figures/pie_met_blood.pdf')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot_large_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "#df_plot_large.loc[:,['amino_acid','templates']].to_csv('Source_Data_Figure5_J_pt2.csv')\n",
    "#df_plot_large.loc[:,['amino_acid','templates']].to_csv('Source_Data_Figure5_J_pt1.csv')\n",
    "#save\n",
    "df_plot_large_pri.to_csv('Source_Ext_Data_Figure9_A_pt1.csv')\n",
    "df_plot_large_met.to_csv('Source_Ext_Data_Figure9_A_pt2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#blood\n",
    "for  s_group_str in ['pORGlow','pORGhigh','liver','lung']:\n",
    "    if s_group_str == 'liver':\n",
    "        ls_liv = [item + '-B' for item in df_tcr_pt[df_tcr_pt.Cohort=='Liver'].Public_Patient_ID]\n",
    "    elif s_group_str == 'lung':\n",
    "        ls_liv = [item + '-B' for item in df_tcr_pt[df_tcr_pt.Cohort=='Lung'].Public_Patient_ID]\n",
    "    elif s_group_str == 'pORGhigh':\n",
    "        ls_liv1 = [item + '-B' for item in df_tcr_pt[df_tcr_pt.pORG_Primary_quartiles=='high'].Public_Patient_ID]\n",
    "        ls_liv2 = [item + '-B' for item in df_tcr_pt[df_tcr_pt.pORG_Met_quartiles=='high'].Public_Patient_ID]\n",
    "        ls_liv = ls_liv1 + ls_liv2\n",
    "    elif s_group_str == 'pORGlow':\n",
    "        ls_liv1 = [item + '-B' for item in df_tcr_pt[df_tcr_pt.pORG_Primary_quartiles=='low'].Public_Patient_ID]\n",
    "        ls_liv2 = [item + '-B' for item in df_tcr_pt[df_tcr_pt.pORG_Met_quartiles=='low'].Public_Patient_ID]\n",
    "        ls_liv = ls_liv1 + ls_liv2\n",
    "    print(s_group_str)\n",
    "    print(f'Primaries {len(set(ls_liv).intersection(set(ls_pri)))}')\n",
    "    print(f'Mets {len(set(ls_liv).intersection(set(ls_met)))}')\n",
    "    \n",
    "    df_plot_large_pri = df_plot_large.loc[df_plot_large.sample_name.isin(set(ls_liv).intersection(set(ls_pri))),['amino_acid','templates']]\n",
    "    df_plot_large_met = df_plot_large.loc[df_plot_large.sample_name.isin(set(ls_liv).intersection(set(ls_met))),['amino_acid','templates']]\n",
    "    df_plot_large_pri = df_plot_large_pri.groupby('amino_acid').sum()\n",
    "    df_plot_large_met = df_plot_large_met.groupby('amino_acid').sum()\n",
    "    i_small_pri = df_plot[(df_plot.loc[:,'templates']<=idx) & (df_plot.sample_name.isin(ls_pri))].templates.sum()\n",
    "    i_small_met = df_plot[(df_plot.loc[:,'templates']<=idx) & (df_plot.sample_name.isin(ls_met))].templates.sum()\n",
    "    print(i_small_pri)\n",
    "    print(i_small_met)\n",
    "    df_plot_large_pri.loc['small'] = i_small_pri\n",
    "    df_plot_large_met.loc['small'] = i_small_met\n",
    "    df_plot_large_pri.to_csv(f'Source_Ext_Data_Figure9_BC_{s_group_str}_pri.csv')\n",
    "    df_plot_large_met.to_csv(f'Source_Ext_Data_Figure9_BC_{s_group_str}_met.csv')\n",
    "    #pri\n",
    "    sizes = df_plot_large_pri.sort_values(by='templates').templates #df_plot_large_pri.loc[:,'templates']\n",
    "    labels = [''] * len(sizes)\n",
    "    fig, ax = plt.subplots(dpi=300)\n",
    "    _ = ax.pie(sizes, labels=labels,autopct = lambda p : f\"{p:.3}%\" if p >1  else f\"\")\n",
    "    fig.savefig(f'figures/pie_primary_blood_{s_group_str}.pdf')\n",
    "    #mets\n",
    "    sizes = df_plot_large_met.sort_values(by='templates').templates #df_plot_large_pri.loc[:,'templates']\n",
    "    labels = [''] * len(sizes)\n",
    "    fig, ax = plt.subplots(dpi=300)\n",
    "    _ = ax.pie(sizes, labels=labels,autopct = lambda p : f\"{p:.3}%\" if p >1  else f\"\")\n",
    "    fig.savefig(f'figures/pie_met_blood_{s_group_str}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pie old\n",
    "# ls_x = ['Type_Site',\n",
    "#     #'Cohort_Met_Site',\n",
    "#         #'Cohort_Primary_Site',\n",
    "#     'pORG_0.2_Met_quartiles_Site',\n",
    "#     'pORG_0.2_Primary_quartiles_Site',\n",
    "#         ]\n",
    "# b_percent = False\n",
    "# for x in ls_x:\n",
    "#     for s_group in df_number.loc[:,x].dropna().unique():\n",
    "#         if s_group.find('_Bld') > -1:\n",
    "#             df_group = df_number[df_number.loc[:,x] == s_group]\n",
    "#             print(s_group)\n",
    "#             richness = np.round(df_group.amino_acid.nunique()/df_group.sample_name.nunique())\n",
    "#             df_plot = df_group.loc[:,['amino_acid','templates']].groupby('amino_acid').sum().sort_values(by='templates').reset_index()\n",
    "#             if b_percent:\n",
    "#                 idx = np.round(df_plot.templates.sum()*.0001,decimals=-1)\n",
    "#             else:\n",
    "#                 if s_group.find('_Bld'):\n",
    "#                     idx = 288 #df_number[df_number.sample_name.str.contains('-B')].sample_name.nunique()\n",
    "#                 else:\n",
    "#                     idx = 216\n",
    "#             print(idx)\n",
    "#             df_plot_large = df_plot[df_plot.loc[:,'templates']>idx].copy()\n",
    "#             i_small = df_plot[df_plot.loc[:,'templates']<=idx].templates.sum()\n",
    "#             if b_percent:\n",
    "#                 df_plot_large.loc[1] = [f'=<0.01%',i_small]\n",
    "#                 df_plot_large.loc[1,'name'] =f'=<0.01%'\n",
    "#             else:\n",
    "#                 df_plot_large.loc[1] = [f'=<{idx}',i_small]\n",
    "#                 df_plot_large.loc[1,'name'] =f'=<{idx}'\n",
    "#             df_plot_large.name.fillna('',inplace=True)\n",
    "#             # plot\n",
    "#             labels = df_plot_large.loc[:,'name'].replace('nan',pd.NA).fillna('')\n",
    "#             sizes = df_plot_large.loc[:,'templates']\n",
    "#             fig, ax = plt.subplots(dpi=300)\n",
    "#             _ = ax.pie(sizes, labels=labels,autopct = lambda p : f\"{p:.3}%\" if p >1  else f\"\")\n",
    "#             if x.find('Cohort') > -1:\n",
    "#                 _ = ax.set_title(f\"{s_group.replace('_',' ')}\\nRichness per pt.={richness}\")\n",
    "#             else:\n",
    "#                 _ = ax.set_title(f\"{s_group.replace('_',' ')}\\n{x.replace('_',' ')}\\nRichness per pt.={richness}\")\n",
    "#             #break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shared pies\n",
    "\n",
    "expanded, shared clones\n",
    "\n",
    "not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #each sample has a total number of templates of an aa rearrangement\n",
    "# df_number = df_tcr_all.groupby(['sample_name','amino_acid']).templates.sum().reset_index()\n",
    "# d_replace = {'B':'Blood', 'M':'Met', 'Ma':'Met', 'Mb':'Met', 'T':'Primary'}\n",
    "# df_number['Site'] = [d_replace[item.split('-')[-1]] for item in df_number.sample_name]\n",
    "# #df_number.loc[df_number.sample_name=='ST-00015839-T','Site'] = 'Met'\n",
    "# df_number['Public_Patient_ID'] = ['ST-' + item.split('-')[1] for item in df_number.sample_name]\n",
    "# df_number['Cohort'] = df_number.Public_Patient_ID.map(dict(zip(df_tcr_pt.Public_Patient_ID,df_tcr_pt.Cohort)))\n",
    "# df_number['Cohort_Site'] = df_number.Cohort + '_' + df_number.Site\n",
    "# for s_porg in ['pORG_All_quartiles','pORG_Primary_quartiles','pORG_Met_quartiles']:\n",
    "#     df_number[s_porg] = df_number.Public_Patient_ID.map(dict(zip(df_tcr_pt.Public_Patient_ID,df_tcr_pt.loc[:,s_porg])))\n",
    "#     df_number[f'{s_porg}_Site'] = df_number.loc[:,s_porg] + '_' + df_number.Site\n",
    "    \n",
    "# #add Type_Site\n",
    "# d_blood_type = dict(zip(df_tcr_pt.Public_Patient_ID + '-B',df_tcr_pt.Blood_Type + '_Bld'))\n",
    "# df_number['Blood_Type'] = df_number.sample_name.map(d_blood_type)#.value_counts()\n",
    "# d_tumor_type = dict(zip(df_tcr_pt.Public_Patient_ID,df_tcr_pt.Tumor_Type + '_Tum'))\n",
    "# df_number['Tumor_Type_temp'] =df_number.Public_Patient_ID.map(d_tumor_type)\n",
    "# df_number['Type_Site'] = df_number['Blood_Type'].fillna(df_number['Tumor_Type_temp'])#\n",
    "# df_number['Cohort_Type_Site'] = df_number.Cohort + '_' + df_number.Type_Site\n",
    "# df_number['Type_Site'].value_counts()\n",
    "# for s_str in ['Primary','Met']:\n",
    "#     df_number[f'Cohort_{s_str}_Site'] = df_number['Cohort_Type_Site']\n",
    "#     df_number.loc[~(df_number.Cohort_Type_Site.str.contains(s_str).fillna(False)),f'Cohort_{s_str}_Site'] = pd.NA#np.nan\n",
    "# df_number['Cohort_Primary_Site'] = [item.replace('Primary','Pri') for item in df_number['Cohort_Primary_Site'].fillna('__')]\n",
    "# df_number['Cohort_Primary_Site'] = df_number.Cohort_Primary_Site.replace('__',np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pie\n",
    "# ls_x = [#'Cohort_Met_Site',\n",
    "#         #'Cohort_Primary_Site',\n",
    "#     'Site',\n",
    "#     #'pORG_Met_quartiles_Site',\n",
    "#     #'pORG_Primary_quartiles_Site',\n",
    "#         ]\n",
    "# b_percent = False\n",
    "# for x in ls_x:\n",
    "#     for s_group in ['Primary', 'Met']: #df_number.loc[:,x].dropna().unique():\n",
    "#              #if  s_group.find('Bl') > -1:\n",
    "#             df_group = df_number[df_number.loc[:,x] == s_group]\n",
    "#             print(s_group)\n",
    "#             richness = np.round(df_group.amino_acid.nunique()/df_group.sample_name.nunique())\n",
    "#             df_plot = df_group.loc[:,['amino_acid','templates']].groupby('amino_acid').sum().sort_values(by='templates').reset_index()\n",
    "#             if b_percent:\n",
    "#                 idx = np.round(df_plot.templates.sum()*.0001,decimals=-1)\n",
    "#             else:\n",
    "#                 idx = df_group.sample_name.nunique()\n",
    "#             print(idx)\n",
    "#             df_plot_large = df_plot[df_plot.loc[:,'templates']>idx].copy()\n",
    "#             df_plot_large['name'] = pd.NA\n",
    "#             i_small = df_plot[df_plot.loc[:,'templates']<=idx].templates.sum()\n",
    "#             if b_percent:\n",
    "#                 df_plot_large.loc[1,'templates'] = [f'=<0.01%',i_small]\n",
    "#                 df_plot_large.loc[1,'name'] =f'=<0.01%'\n",
    "#             else:\n",
    "#                 df_plot_large.loc[1,'templates'] = i_small\n",
    "#                 df_plot_large.loc[1,'name'] = f'=<{idx}'\n",
    "#             df_plot_large.name.fillna('',inplace=True)\n",
    "#             # plot\n",
    "#             labels = df_plot_large.loc[:,'name']\n",
    "#             sizes = df_plot_large.loc[:,'templates']\n",
    "#             fig, ax = plt.subplots(dpi=300)\n",
    "#             _ = ax.pie(sizes, labels=labels,autopct = lambda p : f\"{p:.3}%\" if p >1  else f\"\")\n",
    "#             if x.find('Cohort') > -1:\n",
    "#                 _ = ax.set_title(f\"{s_group.replace('_',' ')}\\nRichness per pt.={richness}\")\n",
    "#             else:\n",
    "#                 _ = ax.set_title(f\"{s_group.replace('_',' ')}\\n{x.replace('_',' ')}\\nRichness per pt.={richness}\")\n",
    "#             fig.savefig(f'figures/pie2_{s_group}_{x}.pdf')\n",
    "#             #break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #ratio\n",
    "# df_bld = df_number[df_number.loc[:,x].str.contains('Blood')]\n",
    "# df_tum = df_number[df_number.loc[:,x].str.contains('Tumor')]\n",
    "# df_tum_bld = pd.DataFrame(df_tum.amino_acid/df_bld.amino_acid)\n",
    "# df_tum_bld[x] = df_tum_bld.index.map(dict(zip(df_tum.index,df_tum.loc[:,x]))).fillna('')\n",
    "# df_tum_bld['Group'] = [item.split('/')[0] for item in df_tum_bld.loc[:,x]]\n",
    "# df_tum_bld['Group'] = df_tum_bld.Group.replace('',np.nan)\n",
    "# pairs = [item for item in itertools.combinations(df_tum_bld.loc[:,'Group'].unique(), 2)]\n",
    "# fig,ax=plt.subplots()\n",
    "# sns.boxplot(data=df_tum_bld,x='Group',y='amino_acid',showfliers=False,ax=ax,order=['high','low'])\n",
    "# sns.stripplot(data=df_tum_bld,x='Group',y='amino_acid',palette='dark',ax=ax,order=['high','low'])\n",
    "# annotator = Annotator(ax=ax, pairs=pairs,data=df_tum_bld,x='Group',y='amino_acid',)\n",
    "# annotator.configure(test='Mann-Whitney', verbose=2).apply_test().annotate()\n",
    "# ax.set_ylabel('ratio tumor to blood')\n",
    "# df_tum_bld.groupby(x).amino_acid.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #plot numbers (old)\n",
    "# import itertools\n",
    "# from statannotations.Annotator import Annotator\n",
    "# #x='pORG_quartile_site'\n",
    "\n",
    "# pairs = [item for item in itertools.combinations(df_number.loc[:,x].unique(), 2)]\n",
    "\n",
    "# fig,ax=plt.subplots()\n",
    "# sns.boxplot(data=df_number,x=x,y='amino_acid',showfliers=False,ax=ax)\n",
    "# sns.stripplot(data=df_number,x=x,y='amino_acid',palette='dark',ax=ax)\n",
    "# annotator = Annotator(ax=ax, pairs=pairs,data=df_number,x=x,y='amino_acid',)\n",
    "# annotator.configure(test='Mann-Whitney', verbose=2).apply_test().annotate()\n",
    "# df_number.groupby(x).amino_acid.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for x in ['Site','quartiles','Tumor Type','Cohort']:#\n",
    "#     df_number_site = df_tcr_all.groupby([x,'sample_name']).amino_acid.nunique().reset_index()\n",
    "#     fig,ax=plt.subplots()\n",
    "#     sns.boxplot(data=df_number_site,x=x,y='amino_acid',showfliers=False,ax=ax)\n",
    "#     sns.stripplot(data=df_number_site,x=x,y='amino_acid',palette='dark',ax=ax)\n",
    "#     pairs = [item for item in itertools.combinations(df_number_site.loc[:,x].unique(), 2)]\n",
    "#     annotator = Annotator(ax=ax, pairs=pairs,data=df_number_site,x=x,y='amino_acid',)\n",
    "#     annotator.configure(test='Mann-Whitney', verbose=2).apply_test().annotate()\n",
    "#     print(df_number_site.groupby(x).amino_acid.median())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s_site in ['Tumor','Blood']:\n",
    "#     for x in ['quartiles','Tumor Type','Cohort']:#\n",
    "#         df_number_site = df_tcr_all[df_tcr_all.Site==s_site].groupby([x,'sample_name']).amino_acid.nunique().reset_index()\n",
    "#         fig,ax=plt.subplots()\n",
    "#         sns.boxplot(data=df_number_site,x=x,y='amino_acid',showfliers=False,ax=ax)\n",
    "#         sns.stripplot(data=df_number_site,x=x,y='amino_acid',palette='dark',ax=ax)\n",
    "#         pairs = [item for item in itertools.combinations(df_number_site.loc[:,x].unique(), 2)]\n",
    "#         annotator = Annotator(ax=ax, pairs=pairs,data=df_number_site,x=x,y='amino_acid',)\n",
    "#         annotator.configure(test='Mann-Whitney', verbose=2).apply_test().annotate()\n",
    "#         print(df_number_site.groupby(x).amino_acid.median())\n",
    "#         ax.set_title(f'{s_site} {x}')\n",
    "#         plt.tight_layout()\n",
    "#         #break\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #tumor only\n",
    "# for s_site in ['Tumor','Blood']:\n",
    "#     for x in ['Cohort']:#\n",
    "#         for s_met_site in ['Met','Primary']:\n",
    "#             df_number_site = df_tcr_all[(df_tcr_all.Site==s_site) & (df_tcr_all.loc[:,'Tumor Type']==s_met_site)].groupby([x,'sample_name']).amino_acid.nunique().reset_index()\n",
    "#             fig,ax=plt.subplots()\n",
    "#             sns.boxplot(data=df_number_site,x=x,y='amino_acid',showfliers=False,ax=ax)\n",
    "#             sns.stripplot(data=df_number_site,x=x,y='amino_acid',palette='dark',ax=ax)\n",
    "#             pairs = [item for item in itertools.combinations(df_number_site.loc[:,x].unique(), 2)]\n",
    "#             annotator = Annotator(ax=ax, pairs=pairs,data=df_number_site,x=x,y='amino_acid',)\n",
    "#             annotator.configure(test='Mann-Whitney', verbose=2).apply_test().annotate()\n",
    "#             print(df_number_site.groupby(x).amino_acid.median())\n",
    "#             ax.set_title(f'{s_site} {s_met_site} {x}')\n",
    "#             plt.tight_layout()\n",
    "#             break\n",
    "#         #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## entropy, simpson's, morisita. gini <a name=\"tcr2\"></a> \n",
    "\n",
    "[contents](#contents)\n",
    "\n",
    "**Jaffee results:** LTS had significantly lower baseline clonality than STS in the anti–CTLA-4 study (P < 0.05, Figure 3). \n",
    "\n",
    "LTS in the anti–PD-1 study had similar baseline clonalities; however, significantly higher clonalities were observed in LTS following 3 cycles of treatment (P < 0.05, Figure 3).\n",
    "\n",
    "anti–CTLA-4 LTS exhibited significantly more expanded clones when compared with STS (P < 0.05). This was not observable in patients treated in the anti–PD-1 study (Figure 4). \n",
    "\n",
    "Because PD-1 blockade affects T cells already localized to the tumor, we analyzed the tumor repertoires of the subset of anti–PD-1 patients for which pre- and posttreatment biopsies were available (n = 12). We observed no significant difference associated with clinical response (n = 8 LTS) or treatment arm (n = 9 in the PD-1 arm) in either the clonality or richness of the repertoires (data not shown).\n",
    "\n",
    "We used a cutoff of 0.1 to stratify repertoires as diverse (clonality <0.1) or clonal (>0.1) and a cutoff of 100 to stratify patients by number of expanded clones, high (>100) or low (<100). The results demonstrated that patients receiving anti–CTLA-4 who had diverse baseline TCR repertoires (n = 16) survived twice as long as patients with clonal repertoires (n = 9), with median survivals of 8.66 and 4.28 months, respectively (P < 0.05). Patients on this study with more than 100 clones expanded after treatment (n = 6) survived nearly 3 times longer than patients with fewer clones expanded (n = 8), with median survivals of 13.23 and 4.55 months, respectively (P < 0.01, Figure 5). The same stratification strategy was unsuccessful when applied to patients on the anti–PD-1 study. Patients with diverse baseline TCR repertoires (n = 12) had a slightly lower median survival to patients with clonal repertoires (n = 20): 5.55 and 8.75 months, respectively (P < 0.05). Likewise, patients with more expanded clones following treatment (n = 4) had similar median survival to patients with fewer (n = 27), at 8.15 and 7.10 months, respectively.\n",
    "\n",
    "\n",
    "The percentage of tumor-exclusive clones was\n",
    "calculated from a list of all rearrangements with ≥10 templates found in both samples combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #right one\n",
    "# import json\n",
    "# #tumor distinct clones; amino acids\n",
    "# # list of all rearrangements with ≥10 templates found in both samples combined\n",
    "# #The percentage of tumor-distinct clones was calculated from a list of all rearrangements with ≥10 templates in each patient’s blood plus tumor samples combined, where tumor distinct clones were defined as those found in tumor samples, but not found in matched blood samples. \n",
    "# # ls_rare = [10] #0,2,5,\n",
    "# # ls_top = [665800] #2,5,10,\n",
    "# # for idx, num_rare in enumerate(ls_rare):\n",
    "# #     print(num_rare)\n",
    "# d_distinct = {}\n",
    "# df_distinct = pd.DataFrame()\n",
    "# ls_un = df_tcr_all[~df_tcr_all.sample_name.str.contains('-B')].sample_name.unique()\n",
    "# for s_sample in ls_un:\n",
    "#         print(s_sample)\n",
    "#         df_sample = df_tcr_all.loc[(df_tcr_all.sample_name==s_sample) | (df_tcr_all.sample_name==s_sample.replace('-T','-B').replace('-M','-B').replace('-Ma','-B').replace('-Mb','-B'))]#.values\n",
    "#         print(df_sample.Public_Patient_ID.iloc[0])\n",
    "#         df_sum_blood_tumor = df_sample.loc[:,['templates','amino_acid']].groupby('amino_acid').sum()\n",
    "#         df_clones = df_sum_blood_tumor[df_sum_blood_tumor.templates>9]\n",
    "#         df_tumor = df_tcr_all.loc[(df_tcr_all.sample_name==s_sample)]\n",
    "#         try:\n",
    "#             df_blood = df_tcr_all.loc[(df_tcr_all.Public_Patient_ID==df_sample.Public_Patient_ID.iloc[0]) & (df_tcr_all.sample_name.str.contains('-B'))]\n",
    "#             es_distinct = (set(df_tumor.amino_acid) - set(df_blood.amino_acid)).intersection(set(df_clones.index))\n",
    "#             i_distinct = len(es_distinct)\n",
    "#             print(i_distinct)\n",
    "#             i_percent = i_distinct/df_tumor[df_tumor.amino_acid.isin(df_clones.index)].amino_acid.nunique()#df_clones[].index.nunique() #how many unique clones\n",
    "#             print(f'{i_percent:.4}')\n",
    "#         except:\n",
    "#             continue\n",
    "#         df_distinct.loc[s_sample,'Number Tumor Distinct Clones'] = i_distinct\n",
    "#         df_distinct.loc[s_sample,'Fraction Tumor Distinct Clones'] = i_percent\n",
    "#         d_distinct.update({s_sample:list(es_distinct)})\n",
    "        \n",
    "# #df_distinct.to_csv(f'Liver_Lung_PDAC/TCR_Tumor_Distinct_Clones_rare{num_rare}to{ls_top[idx]}_all.csv')\n",
    "# with open(\"TCR_tumor_distinct_clones.json\", \"w\") as outfile:\n",
    "#     json.dump(d_distinct, outfile) 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_distinct.to_csv('TCR_calculated_tumor_distinct_clones.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# with open(\"TCR_tumor_distinct_clones.json\", \"w\") as outfile:\n",
    "#     json.dump(d_distinct, outfile)\n",
    "\n",
    " \n",
    "# # Opening JSON file\n",
    "with open('TCR_tumor_distinct_clones.json', 'r') as openfile:\n",
    "    # Reading from json file\n",
    "    d_top50 = json.load(openfile)\n",
    "\n",
    "es_top50 = set()\n",
    "df_kras_tds = pd.DataFrame()\n",
    "for key, item in d_top50.items():\n",
    "    es_top50 = es_top50.union(item)\n",
    "    es_intersect = set(df_kras.CDR3B).intersection(item)\n",
    "    df_kras_tds.loc[key,'No_KRAS'] = len(es_intersect)\n",
    "\n",
    "#any kras?\n",
    "i_intesect = set(df_kras.CDR3B).intersection(es_top50)\n",
    "i_intesect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(es_top50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_union = len(set(df_kras.CDR3B.dropna()).union(es_top50))\n",
    "print(i_union)\n",
    "len(i_intesect)/i_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kras_tds[df_kras_tds.No_KRAS>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient[df_patient.Public_Patient_ID=='ST-00016742'].T[10:69] #low pORG, primary, not lung or liver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_patient[df_patient.Public_Patient_ID=='ST-00015136'].T[10:68]#high pORG, primary, not lung or liver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distinct_load.loc['ST-00017310-T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_patient.loc[:,['Percent Tumor Distinct Clones','Public_Patient_ID']].set_index('Public_Patient_ID')\n",
    "df_test.loc['ST-00017310']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #tumor distinct clones; amino acids\n",
    "# #is this right? is denominatior right?\n",
    "# # list of all rearrangements with ≥10 templates found in both samples combined\n",
    "# ls_rare = [10] #0,2,5,\n",
    "# ls_top = [665800] #2,5,10,\n",
    "# for idx, num_rare in enumerate(ls_rare):\n",
    "#     print(num_rare)\n",
    "#     df_distinct = pd.DataFrame()\n",
    "#     ls_un = df_tcr_all[~df_tcr_all.sample_name.str.contains('-B')].sample_name.unique()\n",
    "#     for s_sample in ls_un:\n",
    "#         print(s_sample)\n",
    "#         df_sample = df_tcr_all.loc[(df_tcr_all.sample_name==s_sample) | (df_tcr_all.sample_name==s_sample.replace('-T','-B').replace('-M','-B').replace('-Ma','-B').replace('-Mb','-B'))]#.values\n",
    "#         print(df_sample.Public_Patient_ID.iloc[0])\n",
    "#         #old original es_rare = set(df_sample.groupby('amino_acid').sum()[df_sample.groupby('amino_acid').sum().templates<num_rare].index)\n",
    "#         #olf tum es_rare = set(df_tumor.groupby('amino_acid').sum()[(df_tumor.groupby('amino_acid').sum().templates>num_rare)&(df_tumor.groupby('amino_acid').sum().templates<=ls_top[idx])].index)\n",
    "#         df_tumor = df_tcr_all.loc[(df_tcr_all.sample_name==s_sample)]\n",
    "#         #all clones between 0 and 2, for example\n",
    "#         es_rare = set(df_sample.groupby('amino_acid').sum()[(df_sample.groupby('amino_acid').sum().templates>num_rare) & (df_sample.groupby('amino_acid').sum().templates<=ls_top[idx])].index)\n",
    "#         print(len(es_rare))\n",
    "#         try:\n",
    "#             df_blood = df_tcr_all.loc[(df_tcr_all.Public_Patient_ID==df_sample.Public_Patient_ID.iloc[0]) & (df_tcr_all.sample_name.str.contains('-B'))]\n",
    "#             #old/old tum = set(df_tumor.amino_acid) - set(df_blood.amino_acid) - es_rare\n",
    "#             es_distinct = (set(df_tumor.amino_acid) - set(df_blood.amino_acid)).intersection(es_rare)\n",
    "#             print(len(es_distinct))\n",
    "#             i_distinct = len(es_distinct)\n",
    "#             #i_percent = i_distinct/(df_tumor[~df_tumor.amino_acid.isin(es_rare)].amino_acid.nunique())\n",
    "#             #i_percent = i_distinct/(df_tumor[df_tumor.amino_acid.isin(es_rare)].amino_acid.nunique()) #how many unique within all tumor small clones\n",
    "#             i_percent = i_distinct/(df_sample[df_sample.amino_acid.isin(es_rare)].amino_acid.nunique()) #how many unique within all small clones\n",
    "#             print(f'{i_percent:.2}')\n",
    "#             i_productive = df_sample[df_sample.amino_acid.isin(es_distinct)].productive_frequency.sum()\n",
    "#         except:\n",
    "#             i_distinct = np.nan\n",
    "#             i_percent = np.nan\n",
    "#         df_distinct.loc[s_sample,'Number Tumor Distinct Clones'] = i_distinct\n",
    "#         df_distinct.loc[s_sample,'Fraction Tumor Distinct Clones'] = i_percent\n",
    "#         df_distinct.loc[s_sample,'Prod. Freq. Tumor Distinct Clones'] = i_productive\n",
    "#         #break\n",
    "\n",
    "#     #df_distinct.to_csv(f'Liver_Lung_PDAC/TCR_Tumor_Distinct_Clones_rare{num_rare}to{ls_top[idx]}_all.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Percent shared. Blood is under sampled (just one TCR, 2 and 5)\n",
    "# ## needs work!\n",
    "# ## Percent shared. Blood is under sampled (just one TCR, 2 and 5)\n",
    "# #amino acids\n",
    "# # percent shared in tumor is just the inverse of tumor distinct clones. so do percent of blood shared.\n",
    "\n",
    "# ls_rare = [0,2,5,10]\n",
    "# ls_top = [2,5,10,665800]\n",
    "# for idx, num_rare in enumerate(ls_rare):\n",
    "#     print(num_rare)\n",
    "#     df_distinct = pd.DataFrame()\n",
    "#     ls_un = df_tcr_all[~df_tcr_all.sample_name.str.contains('-B')].sample_name.unique()\n",
    "#     for s_sample in ls_un:\n",
    "#         print(s_sample)\n",
    "#         df_sample = df_tcr_all.loc[(df_tcr_all.sample_name==s_sample) | (df_tcr_all.sample_name==s_sample.replace('-T','-B').replace('-M','-B').replace('-Ma','-B').replace('-Mb','-B'))]#.values\n",
    "#         print(df_sample.Public_Patient_ID.iloc[0])\n",
    "#         #es_rare = set(df_sample.groupby('amino_acid').sum()[df_sample.groupby('amino_acid').sum().templates<num_rare].index)\n",
    "#         #es_rare = set(df_tumor.groupby('amino_acid').sum()[(df_tumor.groupby('amino_acid').sum().templates>num_rare)&(df_tumor.groupby('amino_acid').sum().templates<=ls_top[idx])].index)\n",
    "#         df_tumor = df_tcr_all.loc[(df_tcr_all.sample_name==s_sample)]\n",
    "#         #all clones between 0 and 2, for example\n",
    "#         es_rare = set(df_sample.groupby('amino_acid').sum()[(df_sample.groupby('amino_acid').sum().templates>num_rare) & (df_sample.groupby('amino_acid').sum().templates<=ls_top[idx])].index)\n",
    "#         print(len(es_rare))\n",
    "#         try:\n",
    "#             df_blood = df_tcr_all.loc[(df_tcr_all.Public_Patient_ID==df_sample.Public_Patient_ID.iloc[0]) & (df_tcr_all.sample_name.str.contains('-B'))]\n",
    "#             #old es_distinct = set(df_blood.amino_acid).intersection(set(df_tumor.amino_acid)) - es_rare #all shared minus rare\n",
    "#             es_distinct = set(df_tumor.amino_acid).intersection(set(df_blood.amino_acid)).intersection(es_rare)\n",
    "#             print(len(es_distinct))\n",
    "#             i_distinct = len(es_distinct)\n",
    "#             #i_percent = i_distinct/(df_blood[~df_blood.amino_acid.isin(es_rare)].amino_acid.nunique())\n",
    "#             # denom all\n",
    "#             #i_percent = i_distinct/(df_sample[~df_sample.amino_acid.isin(es_rare)].amino_acid.nunique())\n",
    "#             i_denom = (df_sample[df_sample.amino_acid.isin(es_rare)].amino_acid.nunique()) #how many unique within all sample small clones\n",
    "#             i_percent = i_distinct/i_denom\n",
    "#             print(f'{i_percent:.2}')\n",
    "#             #i_productive = df_tumor[df_tumor.amino_acid.isin(es_distinct)].productive_frequency.sum()\n",
    "#         except:\n",
    "#             i_distinct = np.nan\n",
    "#             i_percent = np.nan\n",
    "#         df_distinct.loc[s_sample,'Number Blood Shared Clones'] = i_distinct\n",
    "#         df_distinct.loc[s_sample,'Fraction Blood Shared Clones'] = i_percent\n",
    "# #         df_distinct.loc[s_sample,'Prod. Freq. Blood Shared Clones'] = i_productive\n",
    "# #         break\n",
    "# #     break\n",
    "#     #df_distinct.to_csv(f'Liver_Lung_PDAC/TCR_Blood_Shared_Clones_rare{num_rare}_all.csv')\n",
    "#     df_distinct.to_csv(f'Liver_Lung_PDAC/TCR_Blood_Shared_Clones_rare{num_rare}to{ls_top[idx]}_all.csv')\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #tumor distinct clones; rearrangements \n",
    "# df_distinct = pd.DataFrame()\n",
    "# ls_un = df_tcr_all[~df_tcr_all.sample_name.str.contains('-B')].sample_name.unique()\n",
    "# for s_sample in ls_un:\n",
    "#     print(s_sample)\n",
    "#     df_sample = df_tcr_all.loc[(df_tcr_all.sample_name==s_sample) | (df_tcr_all.sample_name==s_sample.replace('-T','-B').replace('-M','-B').replace('-Ma','-B').replace('-Mb','-B'))]#.values\n",
    "#     print(df_sample.Public_Patient_ID.iloc[0])\n",
    "#     #es_rare = set(df_sample[df_sample.templates <10].rearrangement)\n",
    "#     es_rare = set(df_sample.groupby('rearrangement').sum()[df_sample.groupby('rearrangement').sum().templates<10].index)\n",
    "#     print(len(es_rare))\n",
    "#     df_tumor = df_tcr_all.loc[(df_tcr_all.sample_name==s_sample)]\n",
    "#     try:\n",
    "#         df_blood = df_tcr_all.loc[(df_tcr_all.Public_Patient_ID==df_sample.Public_Patient_ID.iloc[0]) & (df_tcr_all.sample_name.str.contains('-B'))]\n",
    "#         es_distinct = set(df_tumor.rearrangement) - set(df_blood.rearrangement) - es_rare\n",
    "#         print(len(es_distinct))\n",
    "#         i_distinct = len(es_distinct)\n",
    "#         i_percent = i_distinct/(df_tumor[~df_tumor.rearrangement.isin(es_rare)].rearrangement.nunique())\n",
    "#         print(f'{i_percent:.2}')\n",
    "#         i_productive = df_tumor[df_tumor.rearrangement.isin(es_distinct)].productive_frequency.sum()\n",
    "#     except:\n",
    "#         i_distinct = np.nan\n",
    "#         i_percent = np.nan\n",
    "#     df_distinct.loc[s_sample,'Number Tumor Distinct Rearrangements'] = i_distinct\n",
    "#     df_distinct.loc[s_sample,'Fraction Tumor Distinct Rearrangements'] = i_percent\n",
    "#     df_distinct.loc[s_sample,'Prod. Freq. Tumor Distinct Rearrangements'] = i_productive\n",
    "#     #break\n",
    "\n",
    "# #df_distinct.to_csv(f'Liver_Lung_PDAC/TCR_Tumor_Distinct_Rearrangements_no_rare_denom.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gini\n",
    "def gini(x):\n",
    "    total = 0\n",
    "    for i, xi in enumerate(x[:-1], 1):\n",
    "        total += np.sum(np.abs(xi - x[i:]))\n",
    "    return total / (len(x)**2 * np.mean(x))\n",
    "\n",
    "#true diversity = 2^ H when H is computed with natural log\n",
    "#scipy.stats.entropy: The logarithmic base to use, defaults to e (natural logarithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#entropy\n",
    "#normalized entropy\n",
    "df_entropy = pd.DataFrame()\n",
    "# def using_groupby():\n",
    "#     groups = [grp for di, grp in df.groupby('D')]\n",
    "#     for itemp, jtemp in inertools.product(groups, repeat=2):\n",
    "s_column = 'productive_frequency'#'templates'#\n",
    "ls_un = set(df_tcr_all.sample_name.unique()) - set(df_entropy.index)\n",
    "for s_sample in ls_un:\n",
    "    print(s_sample)\n",
    "    a_sample = df_tcr_all.loc[df_tcr_all.sample_name==s_sample,s_column].values\n",
    "    S = scipy.stats.entropy(a_sample)\n",
    "    N = df_tcr_all.loc[df_tcr_all.sample_name==s_sample].rearrangement.nunique()\n",
    "    S_norm = S/np.log2(N)\n",
    "    df_entropy.loc[s_sample,'Shannon Entropy'] = S\n",
    "    df_entropy.loc[s_sample,'Normalized Shannon Entropy'] = S_norm\n",
    "    #break\n",
    "\n",
    "#df_entropy.to_csv(f'Liver_Lung_PDAC/TCR_Shannon_entropy_{s_column}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#morisita\n",
    "morisita <- function(x,y){\n",
    "    stopifnot(length(x) == length(y))\n",
    "    prod <- x*y\n",
    "    m <- (2*(sum(prod))) / ((simpson(x) + simpson(y))*sum(x)*sum(y))\n",
    "    m\n",
    "}\n",
    "\n",
    "simpson <- function(x){\n",
    "    x <- x/sum(x)\n",
    "    x <- x^2\n",
    "    l <- sum(x)\n",
    "    l\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Simpson Diversity Index\n",
    "# http://en.wikipedia.org/wiki/Diversity_index\n",
    "\n",
    "# modified from Shannon Diversity Index implementation by audy\n",
    "# https://gist.github.com/audy/783125\n",
    "# https://gist.github.com/audy\n",
    "# D =sum((n / N)^2)\n",
    "# n = the total number of organisms of a particular species\n",
    "# N = the total number of organisms of all species\n",
    "\n",
    "def simpson_di(data):\n",
    "\n",
    "    \"\"\" Given a hash { 'species': count } , returns the Simpson Diversity Index\n",
    "    \n",
    "    >>> simpson_di({'a': 10, 'b': 20, 'c': 30,})\n",
    "    0.3888888888888889\n",
    "    \"\"\"\n",
    "\n",
    "    def p(n, N):\n",
    "        \"\"\" Relative abundance \"\"\"\n",
    "        if n ==  0:\n",
    "            return 0\n",
    "        else:\n",
    "            return float(n)/N\n",
    "\n",
    "    N = sum(data.values())\n",
    "    \n",
    "    return sum(p(n, N)**2 for n in data.values() if n != 0)\n",
    "\n",
    "\n",
    "def inverse_simpson_di(data):\n",
    "    \"\"\" Given a hash { 'species': count } , returns the inverse Simpson Diversity Index\n",
    "    \n",
    "    >>> inverse_simpson_di({'a': 10, 'b': 20, 'c': 30,})\n",
    "    2.571428571428571\n",
    "    \"\"\"\n",
    "    return float(1)/simpson_di(data)\n",
    "\n",
    "# eveness = 1/DS\n",
    "# S is richness\n",
    "\n",
    "## DONE\n",
    "# df_simp = pd.DataFrame()\n",
    "# s_column = 'templates'#'productive_frequency'\n",
    "# ls_un = df_tcr_all.sample_name.unique()\n",
    "# # ls_un = set(df_tcr_all.sample_name.unique()) - set(df_simp.index)\n",
    "# for s_sample in ls_un:\n",
    "#     print(s_sample)\n",
    "#     a_sample = df_tcr_all.loc[df_tcr_all.sample_name==s_sample,s_column].values\n",
    "#     data = dict(zip(range(len(a_sample)),a_sample))\n",
    "#     D = simpson_di(data)\n",
    "#     df_simp.loc[s_sample,'Simpsons_D'] = D\n",
    "#     #break\n",
    "\n",
    "\n",
    "# df_simp['Inverse_Simpsons_D'] = 1/df_simp.Simpsons_D#inv_D #1/D\n",
    "\n",
    "# #save\n",
    "# df_simp.to_csv(f'Liver_Lung_PDAC/TCR_Simpsons_D_{s_column}.csv') #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_simp.to_csv(f'Liver_Lung_PDAC/TCR_Simpsons_D_{s_column}.csv')#.drop('Inverse_Simpsons_D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# evenesss with and without CMV\n",
    "# Simpson's evenness index is the inverse Simpson index divided by the number of species observed, 1 / ( D S ) 1 / (D S) 1/(DS) \n",
    "# S is richness\n",
    "\n",
    "df_simp = pd.DataFrame()\n",
    "s_column = 'templates'#'productive_frequency'\n",
    "ls_un = df_tcr_all.sample_name.unique()\n",
    "# ls_un = set(df_tcr_all.sample_name.unique()) - set(df_simp.index)\n",
    "for s_sample in ls_un:\n",
    "    print(s_sample)\n",
    "    a_sample = df_tcr_all.loc[df_tcr_all.sample_name==s_sample,s_column].values\n",
    "    data = dict(zip(range(len(a_sample)),a_sample))\n",
    "    D = simpson_di(data)\n",
    "    S = len(data)\n",
    "    evenness = 1/(D*S)\n",
    "    df_simp.loc[s_sample,'Simpsons_Evenness'] = evenness\n",
    "    # no cmv\n",
    "    a_sample = df_tcr_all.loc[(df_tcr_all.sample_name==s_sample) & (~df_tcr_all.amino_acid.isin(es_cmv)),s_column].values\n",
    "    data = dict(zip(range(len(a_sample)),a_sample))\n",
    "    D = simpson_di(data)\n",
    "    S = len(data)\n",
    "    evenness = 1/(D*S)\n",
    "    df_simp.loc[s_sample,'Simpsons_Evenness_no_CMV'] = evenness\n",
    "    #break\n",
    "\n",
    "\n",
    "#save\n",
    "#df_simp.to_csv(f'Liver_Lung_PDAC/TCR_Simpsons_Evenness_{s_column}.csv') #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')\n",
    "#f'Liver_Lung_PDAC/TCR_Simpsons_Evenness_{s_column}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old  <a name=\"old\"></a> \n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot number/percent of TCRs shared\n",
    "\n",
    "#old; ended up using productive frequency instead\n",
    "# # add cohorts\n",
    "# for s_sheet in ['Tumor Samples','Blood Samples']:\n",
    "#     df6[s_sheet].loc[df6[s_sheet].loc[:,'Lung Met Present in Patient'] == 'YES','Cohort'] = 'Lung'\n",
    "#     df6[s_sheet].loc[df6[s_sheet].loc[:,'Liver Met Present in Patient'] == 'YES','Cohort'] = 'Liver'\n",
    "#     print(df6[s_sheet]['Cohort'].value_counts())\n",
    "#     d_cohort = dict(zip(df6[s_sheet].loc[:,'Patient ID'],df6[s_sheet].loc[:,'Cohort']))\n",
    "#     if s_sheet == 'Blood Samples':\n",
    "#         b_sample = df_tcr_all.sample_name.str.contains('-B')\n",
    "#         b_sample_je = df_shared_je.index.str.contains('-B')\n",
    "#     else:\n",
    "#         b_sample = ~df_tcr_all.sample_name.str.contains('-B')\n",
    "#         b_sample_je = ~df_shared_je.index.str.contains('-B')\n",
    "#     df_tcr_all.loc[b_sample,'Cohort'] = df_tcr_all.loc[b_sample].Public_Patient_ID.map(d_cohort)\n",
    "#     df_shared_je.loc[b_sample_je,'Cohort'] = df_shared_Public_Patient_IDje.loc[b_sample_je].Public_Patient_ID.map(d_cohort)\n",
    "#     #break\n",
    "\n",
    "# #tumor\n",
    "# df_tcr_all.loc[~df_tcr_all.sample_name.str.contains('-B'),'Site'] = 'Tumor'\n",
    "# df_shared_je.loc[~df_shared_je.index.str.contains('-B'),'Site'] = 'Tumor'\n",
    "# #blood\n",
    "# df_tcr_all.loc[df_tcr_all.sample_name.str.contains('-B'),'Site'] = 'Blood'\n",
    "# df_shared_je.loc[df_shared_je.index.str.contains('-B'),'Site'] = 'Blood'\n",
    "# df_tcr_all['CohortSite'] = df_tcr_all.Cohort + '.' + df_tcr_all.Site \n",
    "# df_shared_je['CohortSite'] = df_shared_je.Cohort + '.' + df_shared_je.Site \n",
    "# #plot number or percent of TCRs that are shared (JE calculated)\n",
    "# for s_col_frac in df_shared_je.columns[df_shared_je.columns.str.contains('Cohort_Liver')]:#'Cohort_Lung' 'Site_Tumor''Site_Blood'\n",
    "#     s_group = s_col_frac.split('_')[1]\n",
    "#     s_frac = s_col_frac.split('_')[2]\n",
    "#     s_col = 'CohortSite'\n",
    "#     ls_groups = df_shared_je.loc[:,s_col].dropna().unique()\n",
    "#     df_shared_je['Percent of Rep. Shared/Clonal'] = df_shared_je.loc[:,s_col_frac]/df_shared_je.Total_Unique_TCRs\n",
    "#     #plot\n",
    "#     plotting = {\"data\": df_shared_je,\"x\": s_col,\"y\": 'Percent of Rep. Shared/Clonal'}\n",
    "#     fig, ax = plt.subplots(figsize=(1.3*len(ls_groups),3),dpi=200)\n",
    "#     sns.stripplot(**plotting,ax=ax,alpha=0.8)\n",
    "#     sns.boxplot(**plotting,ax=ax,showmeans=True,medianprops={'visible': False},\n",
    "#                        whiskerprops={'visible': False},meanline=True,showcaps=False,\n",
    "#                        meanprops={'color': 'k', 'ls': '-', 'lw': 2},showfliers=False,showbox=False)\n",
    "#     pairs = [item for item in itertools.combinations(ls_groups,2)]\n",
    "#     annot = Annotator(ax,pairs,**plotting)\n",
    "#     annot.configure(test='Mann-Whitney',comparisons_correction=\"fdr_bh\", verbose=False)\n",
    "#     ax, test_results = annot.apply_test().annotate()\n",
    "#     ax.set_title(f'Shared in {s_frac} of {s_group} Samples')\n",
    "#     if not (np.array([res.data.pvalue for res in test_results]) < 0.05).any():\n",
    "#         plt.close()\n",
    "# #     else:\n",
    "# #         break\n",
    "\n",
    "# for s_col_frac in df_shared_je.columns[df_shared_je.columns.str.contains('Cohort_Liver')]:#'Cohort_Lung' 'Site_Tumor''Site_Blood'\n",
    "#     s_group = s_col_frac.split('_')[1]\n",
    "#     s_frac = s_col_frac.split('_')[2]\n",
    "#     s_col = 'CohortSite'\n",
    "#     ls_groups = df_shared_je.loc[:,s_col].dropna().unique()\n",
    "#     df_shared_je['Percent of Rep. Shared/Clonal'] = df_shared_je.loc[:,s_col_frac]/df_shared_je.Total_Unique_TCRs\n",
    "#     #plot\n",
    "#     plotting = {\"data\": df_shared_je,\"x\": s_col,\"y\": 'Percent of Rep. Shared/Clonal'}\n",
    "#     fig, ax = plt.subplots(figsize=(1.3*len(ls_groups),3),dpi=200)\n",
    "#     sns.stripplot(**plotting,ax=ax,alpha=0.8)\n",
    "#     sns.boxplot(**plotting,ax=ax,showmeans=True,medianprops={'visible': False},\n",
    "#                        whiskerprops={'visible': False},meanline=True,showcaps=False,\n",
    "#                        meanprops={'color': 'k', 'ls': '-', 'lw': 2},showfliers=False,showbox=False)\n",
    "#     pairs = [item for item in itertools.combinations(ls_groups,2)]\n",
    "#     annot = Annotator(ax,pairs,**plotting)\n",
    "#     annot.configure(test='Mann-Whitney',comparisons_correction=\"fdr_bh\", verbose=False)\n",
    "#     ax, test_results = annot.apply_test().annotate()\n",
    "#     ax.set_title(f'Shared in {s_frac} of {s_group} Samples')\n",
    "#     if not (np.array([res.data.pvalue for res in test_results]) < 0.05).any():\n",
    "#         plt.close()\n",
    "# #     else:\n",
    "# #         break\n",
    "# from statannotations.Annotator import Annotator\n",
    "# import itertools\n",
    "\n",
    "# for s_col_frac in df_shared_je.columns[df_shared_je.columns.str.contains('nunique')]:\n",
    "#     s_col = s_col_frac.split('_')[0]\n",
    "#     s_group = s_col_frac.split('_')[1]\n",
    "#     s_frac = s_col_frac.split('_')[2]\n",
    "#     ls_groups = df_shared_je.loc[:,s_col].dropna().unique()\n",
    "#     df_shared_je['Percent Shared/Clonal'] = df_shared_je.loc[:,s_col_frac]/df_shared_je.Total_Unique_TCRs\n",
    "#     #plot\n",
    "#     plotting = {\"data\": df_shared_je,\"x\": s_col,\"y\": 'Percent Shared/Clonal'}\n",
    "#     fig, ax = plt.subplots(figsize=(1.3*len(ls_groups),3),dpi=200)\n",
    "#     sns.stripplot(**plotting,ax=ax,alpha=0.8)\n",
    "#     sns.boxplot(**plotting,ax=ax,showmeans=True,medianprops={'visible': False},\n",
    "#                        whiskerprops={'visible': False},meanline=True,showcaps=False,\n",
    "#                        meanprops={'color': 'k', 'ls': '-', 'lw': 2},showfliers=False,showbox=False)\n",
    "#     pairs = [item for item in itertools.combinations(ls_groups,2)]\n",
    "#     annot = Annotator(ax,pairs,**plotting)\n",
    "#     annot.configure(test='Mann-Whitney',comparisons_correction=\"fdr_bh\", verbose=False)\n",
    "#     ax, test_results = annot.apply_test().annotate()\n",
    "#     ax.set_title(f'Shared in {s_frac} of {s_group} Samples')\n",
    "#     if  (np.array([res.data.pvalue for res in test_results]) < 0.05).any():\n",
    "#         plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## public vs private\n",
    "# #public versus private - load data\n",
    "# df_patient = pd.read_csv('annotation/20230905_Patient_Metadata.csv',index_col=0)\n",
    "# df_tumor = pd.read_csv(f'Liver_Lung_PDAC/TCR_Fraction_Public_Clones.csv',index_col=0)\n",
    "# df_tumor['Public_Patient_ID'] = ['ST-' + item.split('-')[1] for item in df_tumor.index]\n",
    "# df_tumor = df_tumor.merge(df_patient,on='Public_Patient_ID',suffixes=('','__'))\n",
    "# #blood\n",
    "# df_blood = pd.read_csv(f'Liver_Lung_PDAC/TCR_Fraction_Public_Clones_Blood.csv',index_col=0)\n",
    "# df_blood['Public_Patient_ID'] = ['ST-' + item.split('-')[1] for item in df_blood.index]\n",
    "# df_blood = df_tumor.merge(df_patient,on='Public_Patient_ID',suffixes=('','__'))\n",
    "\n",
    "# # add cohorts\n",
    "# for s_sheet in ['Tumor Samples','Blood Samples']:\n",
    "#     df6[s_sheet].loc[df6[s_sheet].loc[:,'Lung Met Present in Patient'] == 'YES','Cohort'] = 'Lung'\n",
    "#     df6[s_sheet].loc[df6[s_sheet].loc[:,'Liver Met Present in Patient'] == 'YES','Cohort'] = 'Liver'\n",
    "#     print(df6[s_sheet]['Cohort'].value_counts())\n",
    "#     d_cohort = dict(zip(df6[s_sheet].loc[:,'Patient ID'],df6[s_sheet].loc[:,'Cohort']))\n",
    "#     if s_sheet == 'Blood Samples':\n",
    "#         df_blood['Cohort'] = df_blood.Public_Patient_ID.map(d_cohort)\n",
    "#     else:\n",
    "#         df_tumor['Cohort'] = df_tumor.Public_Patient_ID.map(d_cohort)\n",
    "# d_plots = {' Blood ':df_blood,' Tumor ':df_tumor}\n",
    "# for s_type, df in d_plots.items():\n",
    "#     for s_col_frac in df.columns[df.columns.str.contains(s_type)]:\n",
    "#         for s_col in ['Age','Cohort']:\n",
    "#             ls_groups = df.loc[:,s_col].dropna().unique()\n",
    "#             #plot\n",
    "#             plotting = {\"data\": df,\"x\": s_col,\"y\": s_col_frac}\n",
    "#             fig, ax = plt.subplots(figsize=(1.3*len(ls_groups),3),dpi=200)\n",
    "#             sns.stripplot(**plotting,ax=ax,alpha=0.8)\n",
    "#             sns.boxplot(**plotting,ax=ax,showmeans=True,medianprops={'visible': False},\n",
    "#                                whiskerprops={'visible': False},meanline=True,showcaps=False,\n",
    "#                                meanprops={'color': 'k', 'ls': '-', 'lw': 2},showfliers=False,showbox=False)\n",
    "#             pairs = [item for item in itertools.combinations(ls_groups,2)]\n",
    "#             annot = Annotator(ax,pairs,**plotting)\n",
    "#             annot.configure(test='Mann-Whitney',comparisons_correction=\"fdr_bh\", verbose=False)\n",
    "#             ax, test_results = annot.apply_test().annotate()\n",
    "#             #ax.set_title(f'Shared in {s_frac} of {s_group} Samples')\n",
    "# #             if  (np.array([res.data.pvalue for res in test_results]) < 0.05).any():\n",
    "# #                 plt.close()\n",
    "# d_plots = {' Blood ':df_blood,' Tumor ':df_tumor}\n",
    "# for s_type, df in d_plots.items():\n",
    "#     for s_col_frac in df.columns[df.columns.str.contains(s_type)]:\n",
    "#         s_col = 'Age'\n",
    "#         #plot\n",
    "#         plotting = {\"data\": df,\"x\": s_col,\"y\": s_col_frac}\n",
    "# # #old\n",
    "# df_sort = df_tcr_all.sort_values(['sample_name','productive_frequency'],ascending=False).groupby('sample_name').head(50)\n",
    "# #df_tcr_all.groupby('sample_name').sort_values(by='productive_frequency',ascending=False)[0:50].amino_acid\n",
    "# #df_sort.groupby('amino_acid').sample_name.nunique().sort_values()\n",
    "# df_sort['Cohort_Site'] = df_sort.sample_name.map(dict(zip(df_tcr_all.sample_name,df_tcr_all.Cohort_Site)))\n",
    "# # #not working\n",
    "# # for s_cohort, i_count in d_counts.items():\n",
    "# #     print(s_cohort)\n",
    "# #     df_cohort = df_sort[df_sort.Cohort_Site==s_cohort]\n",
    "# #     print(len(df_cohort))\n",
    "# #     b_shared = df_cohort.groupby('amino_acid').sample_name.nunique()/i_count > 0.25\n",
    "# #     print(b_shared.sum())\n",
    "# #     #break\n",
    "\n",
    "# # es_clonal = set(df_tcr_all.sort_values(by='productive_frequency',ascending=False)[0:53].rearrangement)\n",
    "# # print(len(es_clonal))\n",
    "\n",
    "# # es_clonal = set(df_tcr_all.sort_values(by='productive_frequency',ascending=False)[0:53].amino_acid)\n",
    "# # print(len(es_clonal))\n",
    "# # 50 es clonal\n",
    "# # df_share = df_tcr_all[df_tcr_all.amino_acid.isin(es_clonal)].groupby(['amino_acid']).count()\n",
    "# # es_shared = set(df_share[df_share.sample_name > 505*.25].index)\n",
    "# #only gives 4 sequences shared\n",
    "# #tumor\n",
    "# df_tum = df_tcr_all[(df_tcr_all.amino_acid.isin(es_shared)) & (~df_tcr_all.sample_name.str.contains('-B'))]#.Cohort.value_counts()\n",
    "# print(df_tum.groupby('Cohort').sample_name.nunique())\n",
    "\n",
    "# #blood\n",
    "# df_bld = df_tcr_all[(df_tcr_all.amino_acid.isin(es_shared)) & (df_tcr_all.sample_name.str.contains('-B'))]#.Cohort.value_counts()\n",
    "# df_bld.groupby('Cohort').sample_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CMV\n",
    "# df_cmv = pd.read_excel('annotation/41588_2017_BFng3822_MOESM48_ESM.xlsx',sheet_name=0)\n",
    "# #only 1 cmv in the shared\n",
    "# df_cmv[df_cmv.CDR3.isin(es_shared)]\n",
    "# df6['Shared, Clonal Seqs'][df6['Shared, Clonal Seqs'].loc[:,'TCRB CDR3 Amino Acid Sequence']=='CASSPQRNTEAFF']\n",
    "# es_cmv = set(df_tcr_all[df_tcr_all.amino_acid.isin(df_cmv.CDR3)].amino_acid)\n",
    "# len(es_cmv) #should we count the 164 cmv into simpson's diversity or eveness?\n",
    "# #tumor distinct clones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #We defined a TCR sequence as a unique combination of V-CDR3-(amino acid sequence)-J. \n",
    "# #Any TCR sequence found in only 1 donor was “private” and sequences found in more than 1 donor were “public.”\n",
    "# se_public_all = df_tcr_all.groupby('amino_acid').Public_Patient_ID.nunique()\n",
    "# se_public = se_public_all[se_public_all>1] #14% of sequnces are public\n",
    "# #percent public\n",
    "\n",
    "# df_distinct = pd.DataFrame()\n",
    "# ls_un = df_tcr_all[~df_tcr_all.sample_name.str.contains('-B')].sample_name.unique()\n",
    "# for s_sample in ls_un:\n",
    "#     print(s_sample)\n",
    "#     df_sample = df_tcr_all.loc[(df_tcr_all.sample_name==s_sample) | (df_tcr_all.sample_name==s_sample.replace('-T','-B').replace('-M','-B').replace('-Ma','-B').replace('-Mb','-B'))]#.values\n",
    "#     df_tumor = df_tcr_all.loc[(df_tcr_all.sample_name==s_sample)]\n",
    "#     df_blood = df_tcr_all.loc[(df_tcr_all.Public_Patient_ID==df_sample.Public_Patient_ID.iloc[0]) & (df_tcr_all.sample_name.str.contains('-B'))]\n",
    "#     i_distinct = sum(df_tumor.amino_acid.isin(se_public.index))\n",
    "#     i_distinct_bld = sum(df_blood.amino_acid.isin(se_public.index))\n",
    "#     df_distinct.loc[s_sample,'Number Tumor Public Clones'] = i_distinct\n",
    "#     df_distinct.loc[s_sample,'Number Blood Public Clones'] = i_distinct_bld\n",
    "#     try:\n",
    "#         df_distinct.loc[s_sample,'Fraction Tumor Public Clones'] = i_distinct/df_tumor.amino_acid.nunique()\n",
    "#     except: \n",
    "#         df_distinct.loc[s_sample,'Fraction Tumor Public Clones'] = np.nan\n",
    "#     try:\n",
    "#         df_distinct.loc[s_sample,'Fraction Blood Public Clones'] = i_distinct_bld/df_blood.amino_acid.nunique()\n",
    "#     except: \n",
    "#         df_distinct.loc[s_sample,'Fraction Blood Public Clones'] = np.nan\n",
    "#     #print(i_distinct_bld/df_blood.amino_acid.nunique())\n",
    "    \n",
    "\n",
    "# df_distinct.to_csv(f'Liver_Lung_PDAC/TCR_Fraction_Public_Clones.csv')\n",
    "# #percent public (blood)\n",
    "\n",
    "# df_distinct = pd.DataFrame()\n",
    "# ls_un = df_tcr_all[df_tcr_all.sample_name.str.contains('-B')].sample_name.unique()\n",
    "# print(len(ls_un))\n",
    "# for s_sample in ls_un:\n",
    "#     print(s_sample)\n",
    "#     df_sample = df_tcr_all.loc[(df_tcr_all.sample_name==s_sample) | (df_tcr_all.sample_name==s_sample.replace('-T','-B').replace('-M','-B').replace('-Ma','-B').replace('-Mb','-B'))]#.values\n",
    "#     df_blood = df_tcr_all.loc[(df_tcr_all.Public_Patient_ID==df_sample.Public_Patient_ID.iloc[0]) & (df_tcr_all.sample_name.str.contains('-B'))]\n",
    "#     i_distinct_bld = sum(df_blood.amino_acid.isin(se_public.index))\n",
    "#     df_distinct.loc[s_sample,'Number Blood Public Clones'] = i_distinct_bld\n",
    "#     try:\n",
    "#         df_distinct.loc[s_sample,'Fraction Blood Public Clones'] = i_distinct_bld/df_blood.amino_acid.nunique()\n",
    "#     except: \n",
    "#         df_distinct.loc[s_sample,'Fraction Blood Public Clones'] = np.nan\n",
    "    \n",
    "\n",
    "# df_distinct.to_csv(f'Liver_Lung_PDAC/TCR_Fraction_Public_Clones_Blood.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA of pattern of TCRβ repertoire\n",
    "We applied PCA to compare TCRβ clonotype patterns among the primary tumor, normal tissue, and TDLNs \n",
    "in each patient. We used only the information of abundant TCRβ clonotypes \n",
    "(TCRβ sequences observed at the frequencies of 0.05% or higher) in at least one samples. \n",
    "PCA was performed using R command prcomp on R environment 3.4.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = df_tcr_all[df_tcr_all.productive_frequency > 0.0005].loc[:,['sample_name','rearrangement','productive_frequency']]\n",
    "# df_pca = df_test.pivot(columns='rearrangement',index='sample_name', values='productive_frequency')\n",
    "# df_pca['Types'] = [item.split('-')[-1] for item in df_pca.index]\n",
    "\n",
    "# import sklearn\n",
    "# from sklearn.decomposition import TruncatedSVD,PCA\n",
    "# svd = TruncatedSVD(n_components=2, n_iter=7, random_state=42)\n",
    "# X = df_pca.drop('Types',axis=1).fillna(0).values\n",
    "# svd.fit(X)\n",
    "\n",
    "# pca = PCA(n_components=20)\n",
    "# X_r = pca.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Percentage of variance explained for each components\n",
    "# print(\n",
    "#     \"explained variance ratio (first two components): %s\"\n",
    "#     % str(pca.explained_variance_ratio_)\n",
    "# )\n",
    "# y = df_pca.Types #iris.target\n",
    "# plt.figure()\n",
    "# colors = [\"navy\", \"turquoise\", \"darkorange\"]\n",
    "# lw = 2\n",
    "# target_names = ['B', 'T', 'M']\n",
    "# fig, ax = plt.subplots()\n",
    "# for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
    "#     ax.scatter(\n",
    "#         X_r[y == target_name, 0], X_r[y == target_name, 1], color=color, alpha=0.8, lw=lw, label=target_name,\n",
    "#         s=0.5\n",
    "#     )\n",
    "# ax.legend(loc=\"best\", shadow=False, scatterpoints=1)\n",
    "# ax.set_title(\"PCA of TCR dataset\")\n",
    "# #ax.set_xscale(\"log\")\n",
    "# #ax.set_yscale(\"log\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
